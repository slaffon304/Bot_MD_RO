const store = require('../../lib/store');
const content = require('../../content.json');
const { 
    isProKey, 
    gptKeyboard, 
    premiumMsg, 
    resolvePModelByKey 
} = require('../../lib/models');

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY; 

// –°–õ–û–í–ê–†–¨ –ò–ú–ï–ù
const MODEL_NAMES = {
    'gpt5mini': 'GPT-5 Mini',
    'gpt-4o-mini': 'GPT-4o Mini',
    'gpt-4o': 'GPT-4 Omni',
    'claude-3-5-sonnet': 'Claude 3.5 Sonnet',
    'deepseek-chat': 'DeepSeek V3.2',
    'deepseek': 'DeepSeek V3.2',
    'gemini-2.5-flash': 'Gemini 2.5 Flash',
    'gemini-flash': 'Gemini 2.5 Flash',
    'gemini': 'Gemini 2.5 Pro',
    'gemini-pro': 'Gemini 2.5 Pro'
};

const FOOTER_MSG = {
  ru: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ –°–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å: /model | ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏: /settingsbot",
  ro: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ SchimbƒÉ modelul: /model | ‚öôÔ∏è SetƒÉri: /settingsbot",
  en: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ Change model: /model | ‚öôÔ∏è Settings: /settingsbot"
};

// --- AI SERVICE ---
async function chatWithAI(messages, modelKey) {
    if (!OPENROUTER_API_KEY) return "NO_KEY";
    const pmodel = resolvePModelByKey(modelKey) || 'openai/gpt-4o-mini';
    
    try {
        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
                "HTTP-Referer": process.env.VERCEL_URL || 'https://bot.com',
                "X-Title": 'Telegram Bot',
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                "model": pmodel,
                "messages": messages,
                "temperature": 0.7
            })
        });

        if (!response.ok) throw new Error(await response.text());
        const data = await response.json();
        return data.choices[0].message.content;
    } catch (error) {
        console.error("AI Error:", error);
        return null;
    }
}

// --- TEXT HANDLER ---
async function handleTextMessage(ctx, text) {
    if (!text || text.trim().length === 0) return;
    const userId = ctx.from.id.toString();
    await ctx.sendChatAction('typing');

    try {
        // 1. –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        let savedModel = 'gpt5mini';
        let savedLang = 'ru';

        try {
            if (store.getUserModel && store.getUserLang) {
                const [m, l] = await Promise.all([
                    store.getUserModel(userId),
                    store.getUserLang(userId)
                ]);
                if (m) savedModel = m;
                if (l) savedLang = l;
            }
        } catch (e) {
            console.error("[DEBUG] DB Load Error:", e);
        }

        const userData = { model: savedModel, language: savedLang };
        const lang = userData.language;
        
        // 2. –ó–ê–ì–†–£–ó–ö–ê –ò–°–¢–û–†–ò–ò
        let history = [];
        if (store.getHistory) {
            history = await store.getHistory(userId) || [];
            console.log(`[DEBUG] User ${userId} context size: ${history.length}`);
        }

        // 3. –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ú–ü–¢–ê (–° –£–ü–û–†–û–ú –ù–ê –ü–ê–ú–Ø–¢–¨)
        const modelKey = userData.model;
        const niceModelName = MODEL_NAMES[modelKey] || modelKey;

        const systemPrompt = {
            role: "system",
            content: `You are a helpful AI assistant running on the "${niceModelName}" model.
            
            SYSTEM INSTRUCTIONS:
            1. CONTEXT: The messages above are the conversation history. USE IT to answer questions like "what did I just say?" or "repeat that".
            2. IDENTITY: If asked, you are ${niceModelName}.
            3. LANGUAGE: Reply in the SAME language as the user's message.
            4. FALLBACK: Only use ${lang === 'ru' ? 'Russian' : lang === 'ro' ? 'Romanian' : 'English'} if language is unclear.`
        };

        // –°–æ–±–∏—Ä–∞–µ–º –º–∞—Å—Å–∏–≤: –°–∏—Å—Ç–µ–º–∞ -> –ò—Å—Ç–æ—Ä–∏—è -> –¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å
        const messagesToSend = [
            systemPrompt,
            ...history, 
            { role: "user", content: text }
        ];

        const aiResponse = await chatWithAI(messagesToSend, userData.model);

        if (aiResponse === "NO_KEY") {
             await ctx.reply("‚öôÔ∏è API Key is missing.");
             return;
        }
        if (!aiResponse) {
            await ctx.reply("‚ö†Ô∏è AI Service Error.");
            return;
        }

        const footer = FOOTER_MSG[lang] || FOOTER_MSG.en;
        await ctx.reply(aiResponse + footer);

        // 4. –°–û–•–†–ê–ù–ï–ù–ò–ï –ò–°–¢–û–†–ò–ò (–ë–ï–ó–û–ü–ê–°–ù–û–ï)
        if (store.updateConversation) {
            await store.updateConversation(
                userId, 
                { role: "user", content: text }, 
                { role: "assistant", content: aiResponse }
            );
        }

    } catch (error) {
        console.error('Handle Text Error:', error);
        await ctx.reply('‚ùå Error.');
    }
}

async function handleClearCommand(ctx) {
    const userId = ctx.from.id.toString();
    if (store.clearHistory) await store.clearHistory(userId);
    await ctx.reply('üóëÔ∏è History cleared / –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞.');
}

async function handleModelCommand(ctx) {
    const userId = ctx.from.id.toString();
    let lang = 'ru';
    let model = 'gpt5mini';
    
    try {
        if (store.getUserLang) {
            const l = await store.getUserLang(userId);
            if (l) lang = l;
        }
        if (store.getUserModel) {
            const m = await store.getUserModel(userId);
            if (m) model = m;
        }
    } catch(e){}

    const menuText = content.gpt_menu[lang] || content.gpt_menu.en;
    const keyboard = gptKeyboard(lang, model, () => false);

    await ctx.reply(menuText, {
        parse_mode: 'Markdown',
        reply_markup: keyboard 
    });
}

async function handleModelCallback(ctx, langCode) {
    const data = ctx.callbackQuery.data;
    const key = data.replace('model_', ''); 
    const userId = ctx.from.id.toString();

    let currentLang = langCode;
    try {
        if (!currentLang && store.getUserLang) {
            currentLang = await store.getUserLang(userId);
        }
    } catch (e) {}
    if (!currentLang) currentLang = 'ru';

    if (isProKey(key)) {
        const hasPremium = false; 
        if (!hasPremium) {
            const msg = premiumMsg(currentLang);
            await ctx.answerCbQuery(msg, { show_alert: true });
            return;
        }
    }

    // –°–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏ –û–ß–ò–©–ê–ï–¢ –∏—Å—Ç–æ—Ä–∏—é, —á—Ç–æ–±—ã –Ω–µ –ø—É—Ç–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –ò–ò
    if (store.clearHistory) await store.clearHistory(userId);

    if (store.setUserModel) await store.setUserModel(userId, key);

    try {
        const keyboard = gptKeyboard(currentLang, key, () => false);
        await ctx.editMessageReplyMarkup(keyboard); 
    } catch (e) {}

    const niceName = MODEL_NAMES[key] || key;
    
    let replyText = "";
    if (currentLang === 'ru') {
        replyText = `–í—ã –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å ${niceName}. –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å–±—Ä–æ—à–µ–Ω–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã.`;
    } else if (currentLang === 'ro') {
        replyText = `Ai selectat modelul ${niceName}. Istoricul a fost resetat pentru o func»õionare corectƒÉ.`;
    } else {
        replyText = `You selected model ${niceName}. History reset for better performance.`;
    }
    
    replyText += "\n/settingsbot";

    await ctx.reply(replyText);
    await ctx.answerCbQuery();
}

module.exports = {
    handleTextMessage,
    handleClearCommand,
    handleModelCommand,
    handleModelCallback
};
