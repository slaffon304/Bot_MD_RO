const store = require('../../lib/store');
const content = require('../../content.json');
const { 
    isProKey, 
    gptKeyboard, 
    premiumMsg, 
    resolvePModelByKey 
} = require('../../lib/models');

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY; 

const MODEL_CHANGE_MSG = {
  ru: "Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð° Ð½Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¸ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð² /settingsbot.",
  ro: "Modelul selectat este setat la stil normal de comunicare È™i creativitate implicitÄƒ. PoÈ›i configura alÈ›i parametri Ã®n /settingsbot.",
  en: "The selected model is set to normal communication style and creativity by default. You can configure other parameters in /settingsbot."
};

// Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐž: Ð—Ð°Ð¼ÐµÐ½Ð¸Ð» ___ Ð½Ð° Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð»Ð¾Ð¼Ð°Ñ‚ÑŒ Markdown
const FOOTER_MSG = {
  ru: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ Ð¡Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: /model | âš™ï¸ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸: /settingsbot",
  ro: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ SchimbÄƒ modelul: /model | âš™ï¸ SetÄƒri: /settingsbot",
  en: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ Change model: /model | âš™ï¸ Settings: /settingsbot"
};

// --- AI ---
async function chatWithAI(messages, modelKey) {
    if (!OPENROUTER_API_KEY) return "NO_KEY";
    const pmodel = resolvePModelByKey(modelKey) || 'openai/gpt-4o-mini';
    
    try {
        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
                "HTTP-Referer": process.env.VERCEL_URL || 'https://bot.com',
                "X-Title": 'Telegram Bot',
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                "model": pmodel,
                "messages": messages,
                "temperature": 0.7
            })
        });

        if (!response.ok) throw new Error(await response.text());
        const data = await response.json();
        return data.choices[0].message.content;
    } catch (error) {
        console.error("AI Error:", error);
        return null;
    }
}

// --- TEXT ---
async function handleTextMessage(ctx, text) {
    if (!text || text.trim().length === 0) return;
    const userId = ctx.from.id.toString();
    await ctx.sendChatAction('typing');

    try {
        let userData = { language: 'ru', model: 'gpt5mini' };
        try {
            if (store.getUser) {
               const u = await store.getUser(userId);
               if (u) userData = { ...userData, ...u };
            }
        } catch (e) {}

        const lang = userData.language || 'ru';
        let history = [];
        if (store.getHistory) history = await store.getHistory(userId) || [];

        const systemPrompt = {
            role: "system",
            content: `You are a helpful AI. Reply in ${lang === 'ru' ? 'Russian' : lang === 'ro' ? 'Romanian' : 'English'}.`
        };

        const messagesToSend = [
            systemPrompt,
            ...history.slice(-6), 
            { role: "user", content: text }
        ];

        const aiResponse = await chatWithAI(messagesToSend, userData.model);

        if (aiResponse === "NO_KEY") {
             await ctx.reply("âš™ï¸ API Key is missing.");
             return;
        }
        if (!aiResponse) {
            await ctx.reply("âš ï¸ AI Service Error.");
            return;
        }

        const footer = FOOTER_MSG[lang] || FOOTER_MSG.en;
        
        // Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐž: Ð£Ð±Ñ€Ð°Ð» { parse_mode: 'Markdown' }. 
        // Ð­Ñ‚Ð¾ Ð¿Ñ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÐºÑ€Ð°Ñˆ Ð±Ð¾Ñ‚Ð°, ÐµÑÐ»Ð¸ Ð˜Ð˜ Ð¿Ñ€Ð¸ÑˆÐ»ÐµÑ‚ ÑÐ¿ÐµÑ†ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ (*, _, [ Ð¸ Ñ‚.Ð´.)
        await ctx.reply(aiResponse + footer);

        if (store.addToHistory) {
            await store.addToHistory(userId, { role: "user", content: text });
            await store.addToHistory(userId, { role: "assistant", content: aiResponse });
        }

    } catch (error) {
        console.error('Handle Text Error:', error);
        await ctx.reply('âŒ Error.');
    }
}

async function handleClearCommand(ctx) {
    const userId = ctx.from.id.toString();
    if (store.clearHistory) await store.clearHistory(userId);
    await ctx.reply('ðŸ—‘ï¸ History cleared.');
}

async function handleModelCommand(ctx) {
    const userId = ctx.from.id.toString();
    let lang = 'ru';
    let model = 'gpt5mini';
    try {
        const u = await store.getUser(userId);
        if(u) { lang = u.language || 'ru'; model = u.model || 'gpt5mini'; }
    } catch(e){}

    const menuText = content.gpt_menu[lang] || content.gpt_menu.en;
    const keyboard = gptKeyboard(lang, model, () => false);

    await ctx.reply(menuText, {
        parse_mode: 'Markdown',
        reply_markup: keyboard 
    });
}

async function handleModelCallback(ctx, langCode = 'ru') {
    const data = ctx.callbackQuery.data;
    const key = data.replace('model_', ''); 
    const userId = ctx.from.id.toString();

    if (isProKey(key)) {
        const hasPremium = false; 
        if (!hasPremium) {
            const msg = premiumMsg(langCode);
            await ctx.answerCbQuery(msg, { show_alert: true });
            return;
        }
    }

    if (store.setUserModel) await store.setUserModel(userId, key);

    try {
        const keyboard = gptKeyboard(langCode, key, () => false);
        await ctx.editMessageReplyMarkup(keyboard); 
    } catch (e) {}

    const msg = MODEL_CHANGE_MSG[langCode] || MODEL_CHANGE_MSG.ru;
    await ctx.reply(msg);
    
    await ctx.answerCbQuery();
}

module.exports = {
    handleTextMessage,
    handleClearCommand,
    handleModelCommand,
    handleModelCallback
};
    
