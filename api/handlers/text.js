const store = require('../../lib/store');
const content = require('../../content.json');
const { 
    isProKey, 
    gptKeyboard, 
    premiumMsg, 
    resolvePModelByKey 
} = require('../../lib/models');

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY; 

// Ð¡Ð›ÐžÐ’ÐÐ Ð¬ Ð˜ÐœÐ•Ð ÐœÐžÐ”Ð•Ð›Ð•Ð™
const MODEL_NAMES = {
    'gpt5mini': 'GPT-5 Mini',
    'gpt-4o-mini': 'GPT-4o Mini',
    'gpt-4o': 'GPT-4 Omni',
    'claude-3-5-sonnet': 'Claude 3.5 Sonnet',
    'deepseek-chat': 'DeepSeek V3',
    'deepseek-r1': 'DeepSeek R1',
    'gemini-2.5-flash': 'Gemini 2.5 Flash',
    'gemini-2.5-pro': 'Gemini 2.5 Pro',
    'gemini': 'Gemini 2.5',
    'deepseek': 'DeepSeek V3'
};

const MODEL_CHANGE_MSG = {
  ru: "Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð° Ð½Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¸ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð² /settingsbot.",
  ro: "Modelul selectat este setat la stil normal de comunicare È™i creativitate implicitÄƒ. PoÈ›i configura alÈ›i parametri Ã®n /settingsbot.",
  en: "The selected model is set to normal communication style and creativity by default. You can configure other parameters in /settingsbot."
};

const FOOTER_MSG = {
  ru: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ Ð¡Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: /model | âš™ï¸ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸: /settingsbot",
  ro: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ SchimbÄƒ modelul: /model | âš™ï¸ SetÄƒri: /settingsbot",
  en: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ Change model: /model | âš™ï¸ Settings: /settingsbot"
};

// --- AI SERVICE ---
async function chatWithAI(messages, modelKey) {
    if (!OPENROUTER_API_KEY) return "NO_KEY";
    const pmodel = resolvePModelByKey(modelKey) || 'openai/gpt-4o-mini';
    
    try {
        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
                "HTTP-Referer": process.env.VERCEL_URL || 'https://bot.com',
                "X-Title": 'Telegram Bot',
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                "model": pmodel,
                "messages": messages,
                "temperature": 0.7
            })
        });

        if (!response.ok) throw new Error(await response.text());
        const data = await response.json();
        return data.choices[0].message.content;
    } catch (error) {
        console.error("AI Error:", error);
        return null;
    }
}

// --- TEXT HANDLER ---
async function handleTextMessage(ctx, text) {
    if (!text || text.trim().length === 0) return;
    const userId = ctx.from.id.toString();
    await ctx.sendChatAction('typing');

    try {
        // 1. Ð—ÐÐ“Ð Ð£Ð—ÐšÐ Ð”ÐÐÐÐ«Ð¥ (Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐž ÐŸÐžÐ” Ð¢Ð’ÐžÐ™ STORE.JS)
        // ÐœÑ‹ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ ÑÐ·Ñ‹Ðº Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¼Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑÐ¼Ð¸
        let savedModel = null;
        let savedLang = null;

        try {
            if (store.getUserModel) savedModel = await store.getUserModel(userId);
            if (store.getUserLang) savedLang = await store.getUserLang(userId);
            
            console.log(`[DEBUG] User ${userId} loaded: Model=${savedModel}, Lang=${savedLang}`);
        } catch (e) {
            console.error("[DEBUG] DB Load Error:", e);
        }

        const userData = {
            model: savedModel || 'gpt5mini',
            language: savedLang || 'ru'
        };

        const lang = userData.language;
        
        // ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ
        let history = [];
        if (store.getHistory) history = await store.getHistory(userId) || [];

        // 2. ÐžÐŸÐ Ð•Ð”Ð•Ð›Ð•ÐÐ˜Ð• Ð˜ÐœÐ•ÐÐ˜
        const modelKey = userData.model;
        const niceModelName = MODEL_NAMES[modelKey] || modelKey;

        const systemPrompt = {
            role: "system",
            content: `You are a helpful AI assistant running on the "${niceModelName}" model. 
            
            IMPORTANT INSTRUCTIONS:
            1. IDENTITY: If the user asks "what model are you?", answer: "I am an AI based on ${niceModelName}".
            2. LANGUAGE: Reply in the SAME language as the user's message.
            3. FALLBACK: Only use ${lang === 'ru' ? 'Russian' : lang === 'ro' ? 'Romanian' : 'English'} if you cannot detect the language.`
        };

        const messagesToSend = [
            systemPrompt,
            ...history.slice(-6), 
            { role: "user", content: text }
        ];

        const aiResponse = await chatWithAI(messagesToSend, userData.model);

        if (aiResponse === "NO_KEY") {
             await ctx.reply("âš™ï¸ API Key is missing.");
             return;
        }
        if (!aiResponse) {
            await ctx.reply("âš ï¸ AI Service Error.");
            return;
        }

        const footer = FOOTER_MSG[lang] || FOOTER_MSG.en;
        await ctx.reply(aiResponse + footer);

        // 3. Ð¡ÐžÐ¥Ð ÐÐÐ•ÐÐ˜Ð• Ð˜Ð¡Ð¢ÐžÐ Ð˜Ð˜ (Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐž ÐŸÐžÐ” Ð¢Ð’ÐžÐ™ STORE.JS)
        // Ð£ Ñ‚ÐµÐ±Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð½Ð°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ pushMessage, Ð° Ð½Ðµ addToHistory
        if (store.pushMessage) {
            await store.pushMessage(userId, { role: "user", content: text });
            await store.pushMessage(userId, { role: "assistant", content: aiResponse });
        }

    } catch (error) {
        console.error('Handle Text Error:', error);
        await ctx.reply('âŒ Error.');
    }
}

async function handleClearCommand(ctx) {
    const userId = ctx.from.id.toString();
    if (store.clearHistory) await store.clearHistory(userId);
    await ctx.reply('ðŸ—‘ï¸ History cleared.');
}

async function handleModelCommand(ctx) {
    const userId = ctx.from.id.toString();
    let lang = 'ru';
    let model = 'gpt5mini';
    
    try {
        if (store.getUserLang) {
            const l = await store.getUserLang(userId);
            if (l) lang = l;
        }
        if (store.getUserModel) {
            const m = await store.getUserModel(userId);
            if (m) model = m;
        }
    } catch(e){}

    const menuText = content.gpt_menu[lang] || content.gpt_menu.en;
    const keyboard = gptKeyboard(lang, model, () => false);

    await ctx.reply(menuText, {
        parse_mode: 'Markdown',
        reply_markup: keyboard 
    });
}

async function handleModelCallback(ctx, langCode) {
    const data = ctx.callbackQuery.data;
    const key = data.replace('model_', ''); 
    const userId = ctx.from.id.toString();

    // Ð˜Ñ‰ÐµÐ¼ ÑÐ·Ñ‹Ðº Ð² Ð±Ð°Ð·Ðµ
    let currentLang = langCode;
    try {
        if (store.getUserLang) {
            const l = await store.getUserLang(userId);
            if (l) currentLang = l;
        }
    } catch (e) {}
    
    if (!currentLang) currentLang = 'ru';

    if (isProKey(key)) {
        const hasPremium = false; 
        if (!hasPremium) {
            const msg = premiumMsg(currentLang);
            await ctx.answerCbQuery(msg, { show_alert: true });
            return;
        }
    }

    console.log(`[DEBUG] User ${userId} saving model: ${key}`);
    if (store.setUserModel) await store.setUserModel(userId, key);

    try {
        const keyboard = gptKeyboard(currentLang, key, () => false);
        await ctx.editMessageReplyMarkup(keyboard); 
    } catch (e) {}

    const msg = MODEL_CHANGE_MSG[currentLang] || MODEL_CHANGE_MSG.ru;
    await ctx.reply(msg);
    
    await ctx.answerCbQuery();
}

module.exports = {
    handleTextMessage,
    handleClearCommand,
    handleModelCommand,
    handleModelCallback
};
                
