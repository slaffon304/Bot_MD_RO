const store = require('../../lib/store');
const content = require('../../content.json');
const { 
    isProKey, 
    gptKeyboard, 
    premiumMsg, 
    resolvePModelByKey 
} = require('../../lib/models');

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY; 

// 1. Ð¡Ð›ÐžÐ’ÐÐ Ð¬ Ð˜ÐœÐ•Ð (Ð”Ð¾Ð±Ð°Ð²ÑŒ ÑÑŽÐ´Ð° Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ ÐºÐ»ÑŽÑ‡Ð¸ ÑÐ²Ð¾Ð¸Ñ… ÐºÐ½Ð¾Ð¿Ð¾Ðº)
// ÐšÐ»ÑŽÑ‡ ÑÐ»ÐµÐ²Ð° Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°Ñ‚ÑŒ Ñ Ñ‚ÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¾ Ð² ÐºÐ½Ð¾Ð¿ÐºÐ°Ñ… (callback_data)
const MODEL_NAMES = {
    'gpt5mini': 'GPT-5 Mini',
    'gpt-4o-mini': 'GPT-4o Mini',
    'gpt-4o': 'GPT-4 Omni',
    'claude-3-5-sonnet': 'Claude 3.5 Sonnet',
    'deepseek-chat': 'DeepSeek V3',
    'deepseek-r1': 'DeepSeek R1',
    'gemini-2.5-flash': 'Gemini 2.5 Flash',
    'gemini-2.5-pro': 'Gemini 2.5 Pro',
    // Ð•ÑÐ»Ð¸ Ñ‚Ð²Ð¾Ð¸ ÐºÐ»ÑŽÑ‡Ð¸ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð°ÑŽÑ‚ÑÑ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¿Ñ€Ð¾ÑÑ‚Ð¾ 'gemini'), Ð´Ð¾Ð±Ð°Ð²ÑŒ Ð¸Ñ… ÑÑŽÐ´Ð°:
    'gemini': 'Gemini 2.5',
    'deepseek': 'DeepSeek V3'
};

const MODEL_CHANGE_MSG = {
  ru: "Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð° Ð½Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¸ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð² /settingsbot.",
  ro: "Modelul selectat este setat la stil normal de comunicare È™i creativitate implicitÄƒ. PoÈ›i configura alÈ›i parametri Ã®n /settingsbot.",
  en: "The selected model is set to normal communication style and creativity by default. You can configure other parameters in /settingsbot."
};

const FOOTER_MSG = {
  ru: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ Ð¡Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: /model | âš™ï¸ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸: /settingsbot",
  ro: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ SchimbÄƒ modelul: /model | âš™ï¸ SetÄƒri: /settingsbot",
  en: "\n\nâž–âž–âž–âž–âž–âž–\nðŸ”„ Change model: /model | âš™ï¸ Settings: /settingsbot"
};

// --- AI SERVICE ---
async function chatWithAI(messages, modelKey) {
    if (!OPENROUTER_API_KEY) return "NO_KEY";
    // Ð—Ð´ÐµÑÑŒ Ð¼Ñ‹ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ ÐºÐ»ÑŽÑ‡ (gemini) Ð² Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹ Ð´Ð»Ñ API (google/gemini-flash...)
    const pmodel = resolvePModelByKey(modelKey) || 'openai/gpt-4o-mini';
    
    try {
        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
                "HTTP-Referer": process.env.VERCEL_URL || 'https://bot.com',
                "X-Title": 'Telegram Bot',
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                "model": pmodel,
                "messages": messages,
                "temperature": 0.7
            })
        });

        if (!response.ok) throw new Error(await response.text());
        const data = await response.json();
        return data.choices[0].message.content;
    } catch (error) {
        console.error("AI Error:", error);
        return null;
    }
}

// --- TEXT HANDLER ---
async function handleTextMessage(ctx, text) {
    if (!text || text.trim().length === 0) return;
    const userId = ctx.from.id.toString();
    await ctx.sendChatAction('typing');

    try {
        // 2. Ð—ÐÐ“Ð Ð£Ð—ÐšÐ ÐŸÐžÐ›Ð¬Ð—ÐžÐ’ÐÐ¢Ð•Ð›Ð¯
        let userData = { language: 'ru', model: 'gpt5mini' }; // Ð”ÐµÑ„Ð¾Ð»Ñ‚
        
        try {
            if (store.getUser) {
               const u = await store.getUser(userId);
               // Ð›Ð¾Ð³ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸: Ñ‡Ñ‚Ð¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ð»Ð¾ÑÑŒ Ð¸Ð· Ð±Ð°Ð·Ñ‹?
               console.log(`[DEBUG] User ${userId} loaded data:`, u); 
               if (u) userData = { ...userData, ...u };
            }
        } catch (e) {
            console.error("[DEBUG] DB Load Error:", e);
        }

        const lang = userData.language || 'ru';
        let history = [];
        if (store.getHistory) history = await store.getHistory(userId) || [];

        // 3. ÐžÐŸÐ Ð•Ð”Ð•Ð›Ð•ÐÐ˜Ð• Ð˜ÐœÐ•ÐÐ˜ Ð”Ð›Ð¯ ÐŸÐ ÐžÐœÐŸÐ¢Ð
        const modelKey = userData.model || 'gpt5mini';
        // Ð‘ÐµÑ€ÐµÐ¼ ÐºÑ€Ð°ÑÐ¸Ð²Ð¾Ðµ Ð¸Ð¼Ñ Ð¸Ð· ÑÐ»Ð¾Ð²Ð°Ñ€Ñ, Ð»Ð¸Ð±Ð¾ Ñ‡Ð¸ÑÑ‚Ð¸Ð¼ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ
        const niceModelName = MODEL_NAMES[modelKey] || modelKey;

        const systemPrompt = {
            role: "system",
            content: `You are a helpful AI assistant running on the "${niceModelName}" model. 
            
            IMPORTANT INSTRUCTIONS:
            1. IDENTITY: If the user asks "what model are you?", answer: "I am an AI based on ${niceModelName}".
            2. LANGUAGE: Reply in the SAME language as the user's message.
            3. FALLBACK: Only use ${lang === 'ru' ? 'Russian' : lang === 'ro' ? 'Romanian' : 'English'} if you cannot detect the language.`
        };

        const messagesToSend = [
            systemPrompt,
            ...history.slice(-6), 
            { role: "user", content: text }
        ];

        // Ð’ÐÐ–ÐÐž: ÐŸÐµÑ€ÐµÐ´Ð°ÐµÐ¼ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ»ÑŽÑ‡ (modelKey) Ð´Ð»Ñ API, Ð½Ð¾ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ ÑƒÐ¶Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ ÐºÑ€Ð°ÑÐ¸Ð²Ð¾Ðµ Ð¸Ð¼Ñ
        const aiResponse = await chatWithAI(messagesToSend, modelKey);

        if (aiResponse === "NO_KEY") {
             await ctx.reply("âš™ï¸ API Key is missing.");
             return;
        }
        if (!aiResponse) {
            await ctx.reply("âš ï¸ AI Service Error.");
            return;
        }

        const footer = FOOTER_MSG[lang] || FOOTER_MSG.en;
        await ctx.reply(aiResponse + footer);

        if (store.addToHistory) {
            await store.addToHistory(userId, { role: "user", content: text });
            await store.addToHistory(userId, { role: "assistant", content: aiResponse });
        }

    } catch (error) {
        console.error('Handle Text Error:', error);
        await ctx.reply('âŒ Error.');
    }
}

async function handleClearCommand(ctx) {
    const userId = ctx.from.id.toString();
    if (store.clearHistory) await store.clearHistory(userId);
    await ctx.reply('ðŸ—‘ï¸ History cleared.');
}

async function handleModelCommand(ctx) {
    const userId = ctx.from.id.toString();
    let lang = 'ru';
    let model = 'gpt5mini';
    try {
        const u = await store.getUser(userId);
        if(u) { lang = u.language || 'ru'; model = u.model || 'gpt5mini'; }
    } catch(e){}

    const menuText = content.gpt_menu[lang] || content.gpt_menu.en;
    const keyboard = gptKeyboard(lang, model, () => false);

    await ctx.reply(menuText, {
        parse_mode: 'Markdown',
        reply_markup: keyboard 
    });
}

// --- CALLBACK (Ð¡Ð¼ÐµÐ½Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸) ---
async function handleModelCallback(ctx, langCode) {
    const data = ctx.callbackQuery.data;
    const key = data.replace('model_', ''); // Ð¢ÑƒÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÐºÐ»ÑŽÑ‡, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ 'gemini'
    const userId = ctx.from.id.toString();

    // ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑÐ·Ñ‹Ðº
    let currentLang = langCode || 'ru';
    try {
        if (store.getUser) {
            const u = await store.getUser(userId);
            if (u && u.language) currentLang = u.language;
        }
    } catch (e) {}

    if (isProKey(key)) {
        // Ð›Ð¾Ð³Ð¸ÐºÐ° Ð¿Ñ€ÐµÐ¼Ð¸ÑƒÐ¼Ð° (Ð¿Ð¾ÐºÐ° Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°)
        const hasPremium = false; 
        if (!hasPremium) {
            const msg = premiumMsg(currentLang);
            await ctx.answerCbQuery(msg, { show_alert: true });
            return;
        }
    }

    console.log(`[DEBUG] User ${userId} saving model: ${key}`); // Ð›Ð¾Ð³ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
    if (store.setUserModel) await store.setUserModel(userId, key);

    try {
        const keyboard = gptKeyboard(currentLang, key, () => false);
        await ctx.editMessageReplyMarkup(keyboard); 
    } catch (e) {}

    const msg = MODEL_CHANGE_MSG[currentLang] || MODEL_CHANGE_MSG.ru;
    await ctx.reply(msg);
    
    await ctx.answerCbQuery();
}

module.exports = {
    handleTextMessage,
    handleClearCommand,
    handleModelCommand,
    handleModelCallback
};
    
