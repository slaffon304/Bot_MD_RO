const store = require('../../lib/store');
const content = require('../../content.json');
const { 
    GPT_MODELS, // –ü–æ–¥–∫–ª—é—á–∞–µ–º –Ω–∞—à –Ω–æ–≤—ã–π —Å–ø–∏—Å–æ–∫
    isProKey, 
    isVisionModel, // –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑—Ä–µ–Ω–∏—è
    gptKeyboard, 
    premiumMsg, 
    resolvePModelByKey 
} = require('../../lib/models');

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY; 

// –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
const FOOTER_MSG = {
  ru: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ –°–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å: /model | ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏: /settingsbot",
  ro: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ SchimbƒÉ modelul: /model | ‚öôÔ∏è SetƒÉri: /settingsbot",
  en: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ Change model: /model | ‚öôÔ∏è Settings: /settingsbot"
};

// –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è: –ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∞—Å–∏–≤–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏
function getModelNiceName(key, lang = 'ru') {
    const m = GPT_MODELS.find(x => x.key === key);
    if (!m) return key;
    return m.label[lang] || m.label.en || m.key;
}

// --- AI SERVICE ---
async function chatWithAI(messages, modelKey) {
    if (!OPENROUTER_API_KEY) return "NO_KEY";
    // –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π ID (–Ω–∞–ø—Ä–∏–º–µ—Ä, openai/gpt-5-image-mini)
    const pmodel = resolvePModelByKey(modelKey) || 'deepseek/deepseek-chat';
    
    try {
        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
                "HTTP-Referer": process.env.VERCEL_URL || 'https://bot.com',
                "X-Title": 'Telegram Bot',
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                "model": pmodel,
                "messages": messages,
                // –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ 0.7 —Ö–æ—Ä–æ—à–∞ –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–∞, –Ω–æ –¥–ª—è –∫–æ–¥–∞ –ª—É—á—à–µ –Ω–∏–∂–µ.
                // –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é.
                "temperature": 0.7 
            })
        });

        if (!response.ok) throw new Error(await response.text());
        const data = await response.json();
        return data.choices[0].message.content;
    } catch (error) {
        console.error("AI Error:", error);
        return null;
    }
}

// --- MAIN HANDLER ---
async function handleTextMessage(ctx, textInput) {
    // –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ —Ç–µ–∫—Å—Ç –∏–ª–∏ –ø–æ–¥–ø–∏—Å—å, –∏–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞
    const text = textInput || (ctx.message?.caption) || '';
    
    // –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç –∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–µ—Ç - –≤—ã—Ö–æ–¥–∏–º
    if (!text && !ctx.message?.photo && !ctx.message?.document) return;
    
    const userId = ctx.from.id.toString();

    // --- DEBUG COMMAND ---
    if (text === '/debug') {
        if (store.getDebugData) {
            const debugInfo = await store.getDebugData(userId);
            await ctx.reply(`üêû DEBUG INFO:\n\n${debugInfo}`);
        } else {
            await ctx.reply('Debug function not found.');
        }
        return;
    }

    await ctx.sendChatAction('typing');

    try {
        // 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —é–∑–µ—Ä–∞
        let savedModel = 'deepseek'; // –ù–æ–≤—ã–π –¥–µ—Ñ–æ–ª—Ç
        let savedLang = 'ru';
        
        try {
            if (store.getUserModel && store.getUserLang) {
                const [m, l] = await Promise.all([
                    store.getUserModel(userId),
                    store.getUserLang(userId)
                ]);
                if (m) savedModel = m;
                if (l) savedLang = l;
            }
        } catch (e) {}

        const userData = { model: savedModel, language: savedLang };
        const lang = userData.language;

        // 2. –û–ë–†–ê–ë–û–¢–ö–ê –ö–ê–†–¢–ò–ù–ö–ò (VISION LOGIC)
        let photoUrl = null;
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–∏—Å–ª–∞–ª –ª–∏ —é–∑–µ—Ä —Ñ–æ—Ç–æ
        if (ctx.message && ctx.message.photo) {
            // –ë–µ—Ä–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ —Ñ–æ—Ç–æ –∏–∑ –º–∞—Å—Å–∏–≤–∞
            const photos = ctx.message.photo;
            const fileId = photos[photos.length - 1].file_id;
            try {
                const url = await ctx.telegram.getFileLink(fileId);
                photoUrl = url.href;
                console.log(`[Vision] Got photo URL for user ${userId}`);
            } catch (e) {
                console.error("GetFileLink Error:", e);
            }
        }

        // 3. –£–ú–ù–´–ô –ú–ê–†–®–†–£–¢–ò–ó–ê–¢–û–† (AUTO-SWITCH)
        let modelToUse = userData.model;
        
        // –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–æ—Ç–æ, –Ω–æ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å –°–õ–ï–ü–ê–Ø (vision: false)
        if (photoUrl && !isVisionModel(modelToUse)) {
            console.log(`[Auto-Switch] Model ${modelToUse} is blind. Switching to Gemini Flash.`);
            modelToUse = 'gemini_flash'; // –ü–æ–¥–º–µ–Ω—è–µ–º –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—É—é Gemini
        }

        // 4. –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        let history = [];
        if (store.getHistory) {
            history = await store.getHistory(userId) || [];
        }

        // 5. –§–æ—Ä–º–∏—Ä—É–µ–º –°–∏—Å—Ç–µ–º–Ω—ã–π –ü—Ä–æ–º–ø—Ç
        const niceModelName = getModelNiceName(modelToUse, lang);
        const systemPrompt = {
            role: "system",
            content: `You are a helpful AI assistant running on the "${niceModelName}" model.
            
            MEMORY: Use the conversation history above to answer context questions.
            LANGUAGE: Reply in the SAME language as the user's message.
            VISION: If an image is provided, describe it or answer questions about it.`
        };

        // 6. –§–æ—Ä–º–∏—Ä—É–µ–º –°–æ–æ–±—â–µ–Ω–∏–µ –Æ–∑–µ—Ä–∞
        let userMessageContent;

        if (photoUrl) {
            // –§–æ—Ä–º–∞—Ç OpenRouter –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ (Multimodal)
            userMessageContent = [
                { type: "text", text: text || (lang === 'ru' ? "–ß—Ç–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ?" : "Describe this image") },
                { type: "image_url", image_url: { url: photoUrl } }
            ];
        } else {
            // –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            userMessageContent = text;
        }

        const messagesToSend = [
            systemPrompt,
            ...history, 
            { role: "user", content: userMessageContent }
        ];

        // 7. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        const aiResponse = await chatWithAI(messagesToSend, modelToUse);

        if (aiResponse === "NO_KEY") { await ctx.reply("‚öôÔ∏è API Key missing."); return; }
        if (!aiResponse) { await ctx.reply("‚ö†Ô∏è AI Service Error."); return; }

        const footer = FOOTER_MSG[lang] || FOOTER_MSG.en;
        await ctx.reply(aiResponse + footer);

        // 8. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –±–∞–∑—É —Å—Å—ã–ª–∫–∞–º–∏)
        if (store.updateConversation) {
            const historyText = photoUrl ? `[Photo] ${text}` : text;
            await store.updateConversation(
                userId, 
                { role: "user", content: historyText }, 
                { role: "assistant", content: aiResponse }
            );
        }

    } catch (error) {
        console.error('Handle Text Error:', error);
        await ctx.reply('‚ùå Error.');
    }
}

// --- –ö–û–ú–ê–ù–î–´ (–û—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---

async function handleClearCommand(ctx) {
    const userId = ctx.from.id.toString();
    if (store.clearHistory) await store.clearHistory(userId);
    await ctx.reply('üóëÔ∏è History cleared.');
}

async function handleModelCommand(ctx) {
    const userId = ctx.from.id.toString();
    let lang = 'ru';
    let model = 'deepseek'; // –ù–æ–≤—ã–π –¥–µ—Ñ–æ–ª—Ç
    try {
        if (store.getUserLang) lang = await store.getUserLang(userId) || 'ru';
        if (store.getUserModel) model = await store.getUserModel(userId) || 'deepseek';
    } catch(e){}

    const menuText = content.gpt_menu[lang] || content.gpt_menu.en;
    const keyboard = gptKeyboard(lang, model, () => false);
    await ctx.reply(menuText, { parse_mode: 'Markdown', reply_markup: keyboard });
}

async function handleModelCallback(ctx, langCode) {
    const data = ctx.callbackQuery.data;
    const key = data.replace('model_', ''); 
    const userId = ctx.from.id.toString();

    let currentLang = langCode || 'ru';
    try {
        if (!langCode && store.getUserLang) currentLang = await store.getUserLang(userId) || 'ru';
    } catch (e) {}

    if (isProKey(key)) {
        const hasPremium = false; 
        if (!hasPremium) {
            const msg = premiumMsg(currentLang);
            await ctx.answerCbQuery(msg, { show_alert: true });
            return;
        }
    }

    if (store.clearHistory) await store.clearHistory(userId);
    if (store.setUserModel) await store.setUserModel(userId, key);

    try {
        const keyboard = gptKeyboard(currentLang, key, () => false);
        await ctx.editMessageReplyMarkup(keyboard); 
    } catch (e) {}

    const niceName = getModelNiceName(key, currentLang);
    
    let replyText = (currentLang === 'ru') 
        ? `–í—ã –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å ${niceName}. –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å–±—Ä–æ—à–µ–Ω–∞.` 
        : `You selected model ${niceName}. History reset.`;

    await ctx.reply(replyText + "\n/settingsbot");
    await ctx.answerCbQuery();
}

module.exports = {
    handleTextMessage,
    handleClearCommand,
    handleModelCommand,
    handleModelCallback
};
                
