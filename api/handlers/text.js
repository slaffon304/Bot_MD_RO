const store = require('../../lib/store');
const content = require('../../content.json');
const { 
    GPT_MODELS, 
    isProKey, 
    getModelForTask, 
    gptKeyboard, 
    premiumMsg, 
    resolvePModelByKey 
} = require('../../lib/models');

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY; 

const FOOTER_MSG = {
  ru: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ –°–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å: /model | ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏: /settingsbot",
  ro: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ SchimbƒÉ modelul: /model | ‚öôÔ∏è SetƒÉri: /settingsbot",
  en: "\n\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\nüîÑ Change model: /model | ‚öôÔ∏è Settings: /settingsbot"
};

const ASK_FILE_MSG = {
    ru: "üßê –Ø –≤–∏–∂—É —Ñ–∞–π–ª! –ß—Ç–æ –º–Ω–µ —Å –Ω–∏–º —Å–¥–µ–ª–∞—Ç—å? (–û–ø–∏—Å–∞—Ç—å, —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É –∏–ª–∏ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç?)",
    ro: "üßê VƒÉd fi»ôierul! Ce dore»ôti sƒÉ fac cu el? (SƒÉ-l descriu, sƒÉ rezolv o problemƒÉ sau sƒÉ traduc text?)",
    en: "üßê I see the file! What should I do with it? (Describe it, solve a problem, or translate text?)"
};

// --- –õ–ò–ú–ò–¢–´ (10 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –¥–µ–Ω—å) ---
const DAILY_LIMIT = 10;

async function checkAndIncrementLimit(userId) {
    if (!store.redis) return true; // –ï—Å–ª–∏ Redis –Ω–µ—Ç, –ª–∏–º–∏—Ç–æ–≤ –Ω–µ—Ç (–±–µ—Å–∫–æ–Ω–µ—á–Ω–æ)
    
    // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É (—á—Ç–æ–±—ã —Å–±—Ä–∞—Å—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –¥–µ–Ω—å)
    const today = new Date().toISOString().split('T')[0]; // 2023-10-25
    const key = `usage:${today}:${userId}`;
    
    // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    let current = await store.redis.get(key);
    current = parseInt(current) || 0;

    if (current >= DAILY_LIMIT) {
        return false; // –õ–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω
    }

    // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ (+1) –∏ —Å—Ç–∞–≤–∏–º –∂–∏–∑–Ω—å –∫–ª—é—á–∞ 24 —á–∞—Å–∞
    await store.redis.incr(key);
    await store.redis.expire(key, 86400); 
    
    // –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–π —Å—á–µ—Ç—á–∏–∫ –≤ –ø—Ä–æ—Ñ–∏–ª–µ (–¥–ª—è –∫–æ–º–∞–Ω–¥—ã /account)
    await store.redis.incr(`usage:text:${userId}`); 
    
    return true;
}

// --- –ü–û–õ–£–ß–ï–ù–ò–ï –ö–†–ê–°–ò–í–û–ì–û –ò–ú–ï–ù–ò ---
function getModelNiceName(key, lang = 'ru') {
    const m = GPT_MODELS.find(x => x.key === key);
    if (!m) return key;
    return m.label[lang] || m.label.en || m.key;
}

// --- –°–ï–†–í–ò–° –ì–ï–ù–ï–†–ê–¶–ò–ò (Chat & Image) ---
async function openRouterRequest(messages, modelId) {
    if (!OPENROUTER_API_KEY) return null;
    try {
        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
                "HTTP-Referer": process.env.VERCEL_URL || 'https://bot.com',
                "X-Title": 'Telegram Bot',
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                "model": modelId,
                "messages": messages,
                "temperature": 0.7
            })
        });

        if (!response.ok) {
            const errText = await response.text();
            console.error("OpenRouter Error:", errText);
            return "ERROR";
        }
        
        const data = await response.json();
        return data.choices[0].message.content;
    } catch (error) {
        console.error("Fetch Error:", error);
        return "ERROR";
    }
}

// --- MAIN HANDLER ---
async function handleTextMessage(ctx, textInput) {
    const message = ctx.message;
    const caption = message?.caption || '';
    const text = textInput || caption || ''; 
    const userId = ctx.from.id.toString();

    // --- DEBUG ---
    if (text === '/debug') {
        if (store.getDebugData) {
            const debugInfo = await store.getDebugData(userId);
            await ctx.reply(`üêû DEBUG INFO:\n\n${debugInfo}`);
        } else await ctx.reply('Debug not found.');
        return;
    }

    await ctx.sendChatAction('typing');

    try {
        // 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
        let savedModel = 'deepseek'; 
        let savedLang = 'ru';
        let userMode = 'chat';

        try {
            const [m, l, mode] = await Promise.all([
                store.getUserModel(userId),
                store.getUserLang(userId),
                store.getUserMode ? store.getUserMode(userId) : 'chat'
            ]);
            if (m) savedModel = m;
            if (l) savedLang = l;
            if (mode) userMode = mode;
        } catch (e) { console.error("DB Load Error", e); }

        const lang = savedLang;

        // 2. –ü–†–û–í–ï–†–ö–ê –õ–ò–ú–ò–¢–û–í (–ì–õ–û–ë–ê–õ–¨–ù–ê–Ø)
        const isAllowed = await checkAndIncrementLimit(userId);
        if (!isAllowed) {
            const limitMsg = (lang === 'ru') 
                ? "‚õîÔ∏è **–õ–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω**\n–í—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ 10 –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è.\n–ö—É–ø–∏—Ç–µ /premium –¥–ª—è –±–µ–∑–ª–∏–º–∏—Ç–∞."
                : "‚õîÔ∏è **Daily Limit Reached**\nYou used 10 free requests today.\nBuy /premium for unlimited access.";
            await ctx.reply(limitMsg, { parse_mode: 'Markdown' });
            return;
        }

        // --- –í–ï–¢–ö–ê: –†–ò–°–û–í–ê–ù–ò–ï ---
        if (userMode === 'image') {
            if (text) {
                // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ (–±–µ–∑ –ø–æ–≤—Ç–æ—Ä–∞ –ø—Ä–æ–º–ø—Ç–∞)
                const waitMsg = await ctx.reply("üé® Generating...");
                
                // –ú–∞–ø–ø–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
                // gpt5mini (–±–µ—Å–ø–ª–∞—Ç–Ω–∞—è) -> flux-1-schnell (–±—ã—Å—Ç—Ä–∞—è –∏ –¥–µ—à–µ–≤–∞—è)
                // flux (–ø—Ä–µ–º–∏—É–º) -> flux-1-dev (–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è)
                let imageModel = 'black-forest-labs/flux-1-schnell'; 
                
                // –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å –≤ –º–µ–Ω—é (–ª–æ–≥–∏–∫—É –¥–æ–±–∞–≤–∏–º –ø–æ–∑–∂–µ), –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –∑–¥–µ—Å—å
                
                const prompt = `Generate an image: ${text}`;
                
                // –ó–∞–ø—Ä–æ—Å –∫ API
                const result = await openRouterRequest([{ role: "user", content: prompt }], imageModel);

                // –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "Generating..."
                try { await ctx.telegram.deleteMessage(ctx.chat.id, waitMsg.message_id); } catch(e){}

                if (!result || result === "ERROR") {
                    await ctx.reply("‚ö†Ô∏è Image Generation Error. Try again.");
                    return;
                }

                // Flux –Ω–∞ OpenRouter –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ Markdown: ![image](url)
                // –ù–∞–º –Ω—É–∂–Ω–æ –≤—ã—Ç–∞—â–∏—Ç—å URL
                const urlMatch = result.match(/\((https?:\/\/[^\)]+)\)/);
                
                if (urlMatch && urlMatch[1]) {
                    const imageUrl = urlMatch[1];
                    await ctx.replyWithPhoto(imageUrl, { caption: `üñº Generated by ${imageModel}` });
                } else {
                    // –ï—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞—à–ª–∞—Å—å, –∫–∏–¥–∞–µ–º –æ—Ç–≤–µ—Ç —Ç–µ–∫—Å—Ç–æ–º (–∏–Ω–æ–≥–¥–∞ —Ç–∞–º –æ–ø–∏—Å–∞–Ω–∏–µ –æ—à–∏–±–∫–∏)
                    await ctx.reply(result);
                }
                return; 
            }
        }

        // 3. –û–ë–†–ê–ë–û–¢–ö–ê –§–ê–ô–õ–û–í (CHAT MODE)
        let fileUrl = null;
        let fileType = 'text'; 
        const pendingKey = `pending_file:${userId}`;
        
        const isPhoto = message?.photo;
        const isVoice = message?.voice || message?.audio;
        const isVideo = message?.video || message?.video_note;
        const isDoc = message?.document;

        if (isPhoto || isVoice || isVideo || isDoc) {
             try {
                let fileId = null;
                if (isPhoto) { fileId = message.photo[message.photo.length - 1].file_id; fileType = 'image'; }
                else if (isVoice) { fileId = (message.voice || message.audio).file_id; fileType = 'audio'; }
                else if (isVideo) { fileId = (message.video || message.video_note).file_id; fileType = 'video'; }
                else if (isDoc) { fileId = message.document.file_id; fileType = 'doc'; }

                if (fileId) {
                    const urlObj = await ctx.telegram.getFileLink(fileId);
                    fileUrl = urlObj.href;
                    if (!text) {
                        if (store.redis) await store.redis.set(pendingKey, { url: fileUrl, type: fileType }, { ex: 300 });
                        const askText = ASK_FILE_MSG[lang] || ASK_FILE_MSG.en;
                        await ctx.reply(askText);
                        return;
                    }
                }
            } catch (e) { console.error("File error:", e); }
        } else if (text && store.redis) {
            const pending = await store.redis.get(pendingKey);
            if (pending) { fileUrl = pending.url; fileType = pending.type; await store.redis.del(pendingKey); }
        }

        if (!text && !fileUrl) return;

        // 4. –ú–ê–†–®–†–£–¢–ò–ó–ê–¢–û–† (CHAT MODE)
        let modelToUse = savedModel;
        const pmodel = resolvePModelByKey(modelToUse);
        
        if (fileType === 'audio') modelToUse = getModelForTask('audio_input');
        else if (fileType === 'video') modelToUse = getModelForTask('video_input');
        else if (fileType === 'doc') modelToUse = getModelForTask('doc_heavy');
        else if (fileType === 'image') {
             // –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑—Ä–µ–Ω–∏–µ, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º –Ω–∞ Gemini
             // (–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
             if (!pmodel.includes('gpt-4o') && !pmodel.includes('gemini') && !pmodel.includes('claude-3-5')) {
                 modelToUse = 'gemini_flash';
             }
        }

        // 5. –ò–°–¢–û–†–ò–Ø
        let history = [];
        if (store.getHistory) history = await store.getHistory(userId) || [];

        // 6. –ó–ê–ü–†–û–°
        const niceModelName = getModelNiceName(modelToUse, lang);
        const systemPrompt = {
            role: "system",
            content: `You are a helpful AI assistant running on "${niceModelName}". Reply in the SAME language as the user.`
        };

        let userMessageContent;
        if (fileUrl) {
            userMessageContent = [
                { type: "text", text: text || "Describe this." },
                { type: "image_url", image_url: { url: fileUrl } }
            ];
        } else {
            userMessageContent = text;
        }

        const messagesToSend = [
            systemPrompt,
            ...history, 
            { role: "user", content: userMessageContent }
        ];

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π ID –º–æ–¥–µ–ª–∏
        const realModelId = resolvePModelByKey(modelToUse) || 'deepseek/deepseek-chat';
        const aiResponse = await openRouterRequest(messagesToSend, realModelId);

        if (!aiResponse || aiResponse === "ERROR") { await ctx.reply("‚ö†Ô∏è AI Service Error."); return; }

        const footer = FOOTER_MSG[lang] || FOOTER_MSG.en;
        await ctx.reply(aiResponse + footer);

        // 7. –°–û–•–†–ê–ù–ï–ù–ò–ï
        if (store.updateConversation) {
            const historyText = fileUrl ? `[${fileType.toUpperCase()}] ${text}` : text;
            await store.updateConversation(
                userId, 
                { role: "user", content: historyText }, 
                { role: "assistant", content: aiResponse }
            );
        }

    } catch (error) {
        console.error('Handle Text Error:', error);
        await ctx.reply('‚ùå Error.');
    }
}

async function handleClearCommand(ctx) {
    const userId = ctx.from.id.toString();
    if (store.clearHistory) await store.clearHistory(userId);
    await ctx.reply('üóëÔ∏è History cleared.');
}

async function handleModelCommand(ctx) {
    const userId = ctx.from.id.toString();
    let lang = 'ru';
    let model = 'deepseek'; 
    try {
        if (store.getUserLang) lang = await store.getUserLang(userId) || 'ru';
        if (store.getUserModel) model = await store.getUserModel(userId) || 'deepseek';
    } catch(e){}

    const menuText = content.gpt_menu[lang] || content.gpt_menu.en;
    const keyboard = gptKeyboard(lang, model, () => false);
    await ctx.reply(menuText, { parse_mode: 'Markdown', reply_markup: keyboard });
}

async function handleModelCallback(ctx, langCode) {
    const data = ctx.callbackQuery.data;
    const key = data.replace('model_', ''); 
    const userId = ctx.from.id.toString();

    let currentLang = langCode || 'ru';
    try {
        if (!langCode && store.getUserLang) currentLang = await store.getUserLang(userId) || 'ru';
    } catch (e) {}

    if (isProKey(key)) {
        const hasPremium = false; 
        if (!hasPremium) {
            const msg = premiumMsg(currentLang);
            await ctx.answerCbQuery(msg, { show_alert: true });
            return;
        }
    }

    if (store.clearHistory) await store.clearHistory(userId);
    if (store.setUserModel) await store.setUserModel(userId, key);

    try {
        const keyboard = gptKeyboard(currentLang, key, () => false);
        await ctx.editMessageReplyMarkup(keyboard); 
    } catch (e) {}

    const niceName = getModelNiceName(key, currentLang);
    const replyText = (currentLang === 'ru') 
        ? `–í—ã –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å ${niceName}. –ò—Å—Ç–æ—Ä–∏—è —Å–±—Ä–æ—à–µ–Ω–∞.` 
        : `You selected model ${niceName}. History reset.`;

    await ctx.reply(replyText + "\n/settingsbot");
    await ctx.answerCbQuery();
}

module.exports = {
    handleTextMessage,
    handleClearCommand,
    handleModelCommand,
    handleModelCallback
};
        
