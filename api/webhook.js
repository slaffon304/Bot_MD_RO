import { Bot, webhookCallback, InlineKeyboard, Keyboard } from "grammy";
import {
  getHistory, pushMessage, clearHistory,
  getUserModel, setUserModel,
  getUserLang, setUserLang, setLangManual, isLangManual,
  subscribeWeather, unsubscribeWeather,
  setCity, getCity,
  setAwaitingCity, isAwaitingCity, clearAwaitingCity
} from "../lib/store.js";

// â”€â”€ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const provider = (process.env.PROVIDER || "none").toLowerCase();
const envModel = process.env.MODEL || "";
const FORCE_WEB_FOR_OPEN = (process.env.FORCE_WEB_FOR_OPEN ?? "1") !== "0";

function defaultModel() { return envModel || "gpt-4o-mini"; }
function systemPrompt() { return "Ğ¢Ñ‹ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ¸ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° ÑĞ·Ñ‹ĞºĞµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ."; }
function isToolCapableModel(m){ return /gpt-4o/i.test(m); }
function isOpenModelNeedingWeb(m){ return /(meta-llama|llama|mistral)/i.test(m); }

function chunkAndReply(ctx, text) {
  const max = 3800;
  const tasks = [];
  for (let i = 0; i < text.length; i += max) {
    tasks.push(ctx.reply(text.slice(i, i + max), { reply_to_message_id: ctx.message.message_id }));
  }
  return tasks.reduce((p, t) => p.then(() => t), Promise.resolve());
}

// â”€â”€ LLM (OpenRouter) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function getLLMClient() {
  if (provider !== "openrouter") return null;
  const apiKey = process.env.OPENROUTER_API_KEY || "";
  if (!apiKey) return null;
  const OpenAI = (await import("openai")).default;
  return new OpenAI({ apiKey, baseURL: "https://openrouter.ai/api/v1" });
}

// â”€â”€ Ğ¯Ğ·Ñ‹Ğº â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function detectLang(code) {
  const s = (code || "").toLowerCase().split("-")[0];
  if (["ru", "ro", "en"].includes(s)) return s;
  return "en";
}
async function userLang(ctx) {
  const current = detectLang(ctx.from?.language_code);
  const saved = await getUserLang(ctx.from.id);
  const manual = await isLangManual(ctx.from.id);
  if (!saved) { await setUserLang(ctx.from.id, current); return current; }
  if (!manual && current && current !== saved) { await setUserLang(ctx.from.id, current); return current; }
  return saved || current || "en";
}

// â”€â”€ ĞĞ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const NAV = {
  ru: `ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ğŸ‘‹ Ğ¯ Ğ´Ğ°Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ˜Ğ˜ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑÑ‚Ğ°, ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½Ğ¾Ğº, Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸.
Ğ§Ñ‚Ğ¾ ÑƒĞ¼ĞµÑ:
â€¢ ĞŸĞ¸ÑĞ°Ñ‚ÑŒ/Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚Ñ‹, Ğ¾Ğ±ÑŠÑÑĞ½ÑÑ‚ÑŒ, Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ĞºĞ¾Ğ´
â€¢ Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°
â€¢ Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
â€¢ ĞĞ·Ğ²ÑƒÑ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ¸ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ¾Ğ»Ğ¾Ñ
ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ğ¾:
â€¢ ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ â€” ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ñ‹ ÑĞ²ĞµĞ¶Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, ÑÑ…Ğ¾Ğ¶Ñƒ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚
â€¢ /model â€” Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (GPTâ€‘4oâ€‘mini, Llama, Mistral)
â€¢ /new â€” Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³
â€¢ /web Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ â€” Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¸ÑĞº
â€¢ /lang - Ğ²Ñ‹Ğ±Ğ¾Ñ€ ÑĞ·Ñ‹ĞºĞ°
â€¢ /weather [Ğ³Ğ¾Ñ€Ğ¾Ğ´] â€” Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° ÑĞµĞ¹Ñ‡Ğ°Ñ
â€¢ /setcity [Ğ³Ğ¾Ñ€Ğ¾Ğ´] â€” Ğ³Ğ¾Ñ€Ğ¾Ğ´ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
â€¢ /unsubscribe â€” Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑƒÑ‚Ñ€ĞµĞ½Ğ½ÑÑ Ñ€Ğ°ÑÑÑ‹Ğ»ĞºÑƒ
â€¢ /help â€” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹
Ğ¡ĞºĞ¾Ñ€Ğ¾: /img (ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸), /video (Ğ²Ğ¸Ğ´ĞµĞ¾), /tts (Ğ¾Ğ·Ğ²ÑƒÑ‡ĞºĞ°), /stats (ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°)`,
  ro: `Salut! ğŸ‘‹ Acces rapid la AI pentru text, imagini, video È™i muzicÄƒ.
Ce pot:
â€¢ Scriu/traduc texte, explic, scriu cod
â€¢ Generez imagini È™i video
â€¢ Lucrez cu documente
â€¢ TTS È™i recunoaÈ™tere voce
Util:
â€¢ Scrie un mesaj â€” dacÄƒ e nevoie, caut pe internet
â€¢ /model â€” alege modelul (GPTâ€‘4oâ€‘mini, Llama, Mistral)
â€¢ /new â€” dialog nou
â€¢ /web Ã®ntrebare â€” cÄƒutare web manualÄƒ
â€¢ /lang - alegeÈ›i limba
â€¢ /weather [oraÈ™] â€” meteo acum
â€¢ /setcity [oraÈ™] â€” oraÈ™ implicit
â€¢ /unsubscribe â€” opreÈ™te prognoza de dimineaÈ›Äƒ
â€¢ /help â€” comenzi
Ãn curÃ¢nd: /img, /video, /tts, /stats`,
  en: `Hi! ğŸ‘‹ Access top AI for text, images, video, and music.
I can:
â€¢ Write/translate text, explain, write code
â€¢ Generate images and video
â€¢ Work with documents
â€¢ TTS and speech-to-text
Useful:
â€¢ Just type â€” I'll use the web if fresh data is needed
â€¢ /model â€” choose a model (GPTâ€‘4oâ€‘mini, Llama, Mistral)
â€¢ /new â€” new chat
â€¢ /web query â€” manual web search
â€¢ /lang - choose lanquage
â€¢ /weather [city] â€” weather now
â€¢ /setcity [city] â€” default city
â€¢ /unsubscribe â€” stop morning weather
â€¢ /help â€” commands
Coming soon: /img, /video, /tts, /stats`
};
const BTN = {
  ru: { share: "ğŸ“ ĞŸĞ¾Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸ĞµĞ¹", type: "âœï¸ Ğ£ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ³Ğ¾Ñ€Ğ¾Ğ´", ask: "Ğ§Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñ‹ Ğ² 06:00, Ğ¿Ğ¾Ğ´ĞµĞ»Ğ¸Ñ‚ĞµÑÑŒ Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸ĞµĞ¹ Ğ¸Ğ»Ğ¸ Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Â«âœï¸ Ğ£ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ³Ğ¾Ñ€Ğ¾Ğ´Â»" },
  ro: { share: "ğŸ“ Trimite locaÈ›ia",     type: "âœï¸ SeteazÄƒ oraÈ™ul", ask: "Pentru a primi prognozÄƒ meteo la 06:00, trimite locaÈ›ia sau apasÄƒ Â«âœï¸ SeteazÄƒ oraÈ™ulÂ»" },
  en: { share: "ğŸ“ Share location",       type: "âœï¸ Set city",       ask: "For 06:00 forecast, share location or tap Â«âœï¸ Set cityÂ»" }
};

// â”€â”€ ĞŸĞ¾Ğ¸ÑĞº (Tavily) Ğ¸ ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function tavilySearch(query, maxResults = 5) {
  const key = process.env.TAVILY_API_KEY || "";
  if (!key) return { ok: false, error: "NO_TAVILY_KEY" };
  const resp = await fetch("https://api.tavily.com/search", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      api_key: key, query,
      search_depth: "basic", include_answer: false, time_range: "d",
      max_results: Math.min(Math.max(maxResults, 1), 8)
    })
  });
  if (!resp.ok) return { ok: false, error: `HTTP_${resp.status}` };
  const data = await resp.json();
  return { ok: true, data };
}
async function summarizeWithSources(question, searchData, model) {
  const client = await getLLMClient();
  if (!client) throw new Error("NO_LLM");
  const sources = (searchData?.results || []).slice(0, 5);
  if (!sources.length) return "ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°ÑˆÑ‘Ğ» Ğ¿Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ.";
  const list = sources.map((s, i) => `${i + 1}. ${s.title || s.url} â€” ${s.url}`).join("\n");
  const extracts = sources.map((s, i) => `[${i + 1}] ${String(s.content || "").slice(0, 800)}`).join("\n\n");
  const messages = [
    { role: "system", content: "Ğ¢Ñ‹ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ„Ğ°ĞºÑ‚Ñ‹ Ğ¸Ğ· 'Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²'. Ğ”ĞµĞ»Ğ°Ğ¹ Ğ¼Ğ°Ñ€ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿ÑƒĞ½ĞºÑ‚Ñ‹. Ğ¡ÑÑ‹Ğ»ĞºĞ¸ ÑÑ‚Ğ°Ğ²ÑŒ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ Ğ¿Ğ¾ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ°Ğ¼ [1], [2], Ğ° Ğ² ĞºĞ¾Ğ½Ñ†Ğµ â€” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²." },
    { role: "user", content: `Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: ${question}\n\nĞ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n${list}\n\nĞ’Ñ‹Ğ´ĞµÑ€Ğ¶ĞºĞ¸:\n${extracts}` }
  ];
  const r = await client.chat.completions.create({ model, temperature: 0.2, max_tokens: 450, messages });
  return r.choices?.[0]?.message?.content || "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚.";
}
async function plainChat({ text, hist, model }) {
  const client = await getLLMClient(); if (!client) throw new Error("NO_LLM");
  const messages = [{ role: "system", content: systemPrompt() }, ...hist, { role: "user", content: text }];
  const r = await client.chat.completions.create({ model, temperature: 0.6, max_tokens: 400, messages });
  return r.choices?.[0]?.message?.content || "ĞĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¾Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.";
}
async function chatWithAutoSearch({ text, hist, model }) {
  const client = await getLLMClient(); if (!client) throw new Error("NO_LLM");
  const tools = [{
    type: "function",
    function: {
      name: "web_search",
      description: "ĞŸĞ¾Ğ¸ÑĞº Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ Ğ´Ğ»Ñ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
      parameters: { type: "object", properties: { query: { type: "string" }, max_results: { type: "integer", default: 5 } }, required: ["query"] }
    }
  }];
  const r1 = await client.chat.completions.create({
    model, temperature: 0.6, max_tokens: 300,
    messages: [{ role: "system", content: "Ğ•ÑĞ»Ğ¸ Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ½ÑƒĞ¶Ğ½Ñ‹ ÑĞ²ĞµĞ¶Ğ¸Ğµ Ñ„Ğ°ĞºÑ‚Ñ‹ (Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°, ĞºÑƒÑ€ÑÑ‹, Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚.Ğ¿.), Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¸ web_search. Ğ˜Ğ½Ğ°Ñ‡Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ÑĞ°Ğ¼." }, ...hist, { role: "user", content: text }],
    tools, tool_choice: "auto"
  });
  const msg1 = r1.choices?.[0]?.message;
  const toolCalls = msg1?.tool_calls || [];
  if (toolCalls.length > 0) {
    const call = toolCalls.find((c) => c.function?.name === "web_search") || toolCalls[0];
    let args = {}; try { args = JSON.parse(call.function?.arguments || "{}"); } catch {}
    const q = (args.query || text).toString();
    const maxRes = Number(args.max_results || 5);
    const sr = await tavilySearch(q, maxRes);
    if (!sr.ok) return sr.error === "NO_TAVILY_KEY" ? "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ TAVILY_API_KEY Ğ² Vercel (Production) Ğ¸ Redeploy." : `ĞŸĞ¾Ğ¸ÑĞº Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑÑ (${sr.error}).`;
    return await summarizeWithSources(q, sr.data, model);
  }
  const plain = msg1?.content?.trim(); if (plain) return plain;
  return "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·.";
}

// â”€â”€ Ğ“ĞµĞ¾ĞºĞ¾Ğ´Ğ¸Ğ½Ğ³ Ğ¸ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function geocodeCity(name, lang) {
  const u = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(name)}&count=1&language=${lang || "en"}`;
  const r = await fetch(u); const j = await r.json(); const g = j?.results?.[0];
  if (!g) return null;
  return { name: `${g.name}${g.country ? ", " + g.country : ""}`, lat: g.latitude, lon: g.longitude };
}
async function reverseGeocode(lat, lon, lang) {
  try {
    const u = `https://geocoding-api.open-meteo.com/v1/reverse?latitude=${lat}&longitude=${lon}&language=${lang || "en"}&count=1`;
    const r = await fetch(u); const j = await r.json(); const g = j?.results?.[0];
    return g ? `${g.name}${g.country ? ", " + g.country : ""}` : null;
  } catch { return null; }
}
async function weatherNow(lat, lon) {
  const u = `https://api.open-meteo.com/v1/forecast?latitude=${lat}&longitude=${lon}&current_weather=true&hourly=temperature_2m,precipitation,wind_speed_10m&daily=temperature_2m_max,temperature_2m_min,precipitation_probability_max&timezone=auto`;
  const r = await fetch(u);
  return await r.json();
}
function formatWeatherNow(w, lang, place) {
  const t = w?.current_weather?.temperature;
  const ws = w?.current_weather?.windspeed;
  const maxt = w?.daily?.temperature_2m_max?.[0];
  const mint = w?.daily?.temperature_2m_min?.[0];
  const pr = w?.daily?.precipitation_probability_max?.[0];
  const L = {
    ru: () => `ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ°: ${place}\nâ€¢ Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ: ${t}Â°C, Ğ²ĞµÑ‚ĞµÑ€ ${ws} Ğ¼/Ñ\nâ€¢ Ğ”Ğ½Ñ‘Ğ¼: ${maxt}Â°C, Ğ½Ğ¾Ñ‡ÑŒÑ: ${mint}Â°C\nâ€¢ ĞÑĞ°Ğ´ĞºĞ¸: ${pr}%`,
    ro: () => `Meteo: ${place}\nâ€¢ Acum: ${t}Â°C, vÃ¢nt ${ws} m/s\nâ€¢ Zi: ${maxt}Â°C, noapte: ${mint}Â°C\nâ€¢ Ploaie: ${pr}%`,
    en: () => `Weather: ${place}\nâ€¢ Now: ${t}Â°C, wind ${ws} m/s\nâ€¢ Day: ${maxt}Â°C, night: ${mint}Â°C\nâ€¢ Precip.: ${pr}%`
  };
  const f = L[lang] || L.en;
  return f();
}

// â”€â”€ ĞœĞ¾Ğ´ĞµĞ»Ğ¸ /model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MODEL_OPTIONS = [
  { id: "gpt-4o-mini", label: "gpt-4o-mini (ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾/Ğ½ĞµĞ´Ğ¾Ñ€Ğ¾Ğ³Ğ¾)" },
  { id: "meta-llama/llama-3.1-70b-instruct", label: "Llama 3.1 70B (Ğ±ÑĞ´Ğ¶ĞµÑ‚)" },
  { id: "mistralai/mistral-small", label: "Mistral Small (Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾/Ğ´ĞµÑˆĞµĞ²Ğ¾)" }
];
const KNOWN_CMDS = new Set(["start","help","lang ru","lang ro","lang en","unsubscribe","setcity","weather","new","model","web"]);

// â”€â”€ Ğ‘Ğ¾Ñ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let bot;
function getBot() {
  if (bot) return bot;
  const token = process.env.TELEGRAM_BOT_TOKEN;
  if (!token) return null;
  const b = new Bot(token);

  // ĞŸÑ€ĞµĞ´-Ğ¼Ğ¸Ğ´Ğ»Ğ²Ğ°Ñ€: Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ° + Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
  b.use(async (ctx, next) => {
    if (ctx.message?.text) {
      const text = ctx.message.text.trim();

      // Ğ•ÑĞ»Ğ¸ Ğ¶Ğ´Ñ‘Ğ¼ Ğ³Ğ¾Ñ€Ğ¾Ğ´ â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ±Ğ»Ğ¸Ğ¶Ğ°Ğ¹ÑˆĞ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚ ĞºĞ°Ğº Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°
      if (await isAwaitingCity(ctx.from.id) && !text.startsWith("/")) {
        const lang = await userLang(ctx);
        const g = await geocodeCity(text, lang);
        await clearAwaitingCity(ctx.from.id);
        if (!g) { await ctx.reply(lang === "ro" ? "Nu am gÄƒsit oraÈ™ul." : (lang === "en" ? "City not found." : "Ğ“Ğ¾Ñ€Ğ¾Ğ´ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½.")); return; }
        await setCity(ctx.from.id, g);
        await ctx.reply((lang === "ro" ? "Setat: " : (lang === "en" ? "Set: " : "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½: ")) + `${g.name} (${g.lat.toFixed(2)}, ${g.lon.toFixed(2)})`);
        return; // Ğ½Ğµ Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ´Ğ°Ğ»ÑŒÑˆĞµ Ğ² Ñ‡Ğ°Ñ‚-LLM
      }

      // ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°
      if (text.startsWith("/")) {
        const m = text.match(/^\/(\w+)/);
        const cmd = (m?.[1] || "").toLowerCase();
        if (cmd && !KNOWN_CMDS.has(cmd)) {
          const lang = await userLang(ctx);
          const msg = lang === "ro" ? "ComandÄƒ necunoscutÄƒ. Vezi /help." : (lang === "en" ? "Unknown command. See /help." : "ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°. Ğ¡Ğ¼Ğ¾Ñ‚Ñ€Ğ¸ /help.");
          await ctx.reply(msg);
          return;
        }
      }
    }
    await next();
  });

  b.command("start", async (ctx) => {
    const lang = await userLang(ctx);
    await subscribeWeather(ctx.from.id, ctx.chat.id);

    const kb = new Keyboard()
      .requestLocation(BTN[lang].share).row()
      .text(BTN[lang].type)
      .resized().oneTime();
    await ctx.reply(BTN[lang].ask, { reply_markup: kb });
    await ctx.reply(NAV[lang]);
  });

  b.command("help", async (ctx) => {
    const lang = await userLang(ctx);
    await ctx.reply(NAV[lang]);
  });

  b.command("lang", async (ctx) => {
    const v = ((ctx.message.text || "").trim().split(/\s+/)[1] || "").toLowerCase();
    if (!["ru","ro","en"].includes(v)) { await ctx.reply("Use: /lang ru | ro | en"); return; }
    await setUserLang(ctx.from.id, v);
    await setLangManual(ctx.from.id, true); // Ñ„Ğ¸ĞºÑĞ¸Ñ€ÑƒĞµĞ¼ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€
    await ctx.reply("OK");
    await ctx.reply(NAV[v]);
  });

  b.command("unsubscribe", async (ctx) => {
    await unsubscribeWeather(ctx.from.id);
    await ctx.reply("Ğ Ğ°ÑÑÑ‹Ğ»ĞºĞ° Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñ‹ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°.");
  });

  b.command("setcity", async (ctx) => {
    const lang = await userLang(ctx);
    const arg = (ctx.message.text || "").replace(/^\/setcity(@\S+)?\s*/i, "").trim();
    if (!arg) {
      // Ğ’ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Â«Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°Â» Ğ¸ Ğ¿Ñ€Ğ¾ÑĞ¸Ğ¼ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ
      await setAwaitingCity(ctx.from.id, 600);
      const msg = lang === "ro" ? "Scrie numele oraÈ™ului Ã®n urmÄƒtorul mesaj." :
                  (lang === "en" ? "Type the city name in the next message." :
                                   "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ° ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ĞµĞ¼.");
      await ctx.reply(msg);
      return;
    }
    const g = await geocodeCity(arg, lang);
    if (!g) { await ctx.reply(lang === "ro" ? "Nu am gÄƒsit oraÈ™ul." : (lang === "en" ? "City not found." : "Ğ“Ğ¾Ñ€Ğ¾Ğ´ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½.")); return; }
    await setCity(ctx.from.id, g);
    await ctx.reply((lang === "ro" ? "Setat: " : (lang === "en" ? "Set: " : "Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½: ")) + `${g.name} (${g.lat.toFixed(2)}, ${g.lon.toFixed(2)})`);
  });

  b.command("weather", async (ctx) => {
    const lang = await userLang(ctx);
    let g = await getCity(ctx.from.id);
    const arg = (ctx.message.text || "").replace(/^\/weather(@\S+)?\s*/i, "").trim();
    if (arg) g = (await geocodeCity(arg, lang)) || g;
    if (!g) { await ctx.reply(lang === "ro" ? "Trimite locaÈ›ia sau foloseÈ™te /setcity OraÈ™" : (lang === "en" ? "Share location or use /setcity City" : "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸Ñ Ğ¸Ğ»Ğ¸ /setcity Ğ“Ğ¾Ñ€Ğ¾Ğ´")); return; }
    const w = await weatherNow(g.lat, g.lon);
    await ctx.reply(formatWeatherNow(w, lang, g.name));
  });

  b.on("message:location", async (ctx) => {
    const lang = await userLang(ctx);
    const { latitude, longitude } = ctx.message.location;
    const name = (await reverseGeocode(latitude, longitude, lang)) || "";
    await clearAwaitingCity(ctx.from.id);
    await setCity(ctx.from.id, { name: name || "â€”", lat: latitude, lon: longitude });
    await ctx.reply((lang === "ro" ? "Salvat locul: " : (lang === "en" ? "Saved: " : "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾: ")) + (name || `${latitude.toFixed(2)}, ${longitude.toFixed(2)}`));
  });

  b.command("new", async (ctx) => {
    await clearHistory(ctx.chat.id);
    await ctx.reply("ĞĞºĞµĞ¹, Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³.");
  });

  b.command("model", async (ctx) => {
    const kb = new InlineKeyboard();
    for (const m of MODEL_OPTIONS) kb.text(m.label, `m:${m.id}`).row();
    await ctx.reply("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ:", { reply_markup: kb });
  });
  b.callbackQuery(/m:.+/, async (ctx) => {
    const data = ctx.callbackQuery.data || "";
    const chosen = data.split(":")[1];
    const found = MODEL_OPTIONS.find((m) => m.id === chosen);
    if (!found) { await ctx.answerCallbackQuery({ text: "ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ", show_alert: true }); return; }
    await setUserModel(ctx.from.id, found.id);
    await ctx.answerCallbackQuery({ text: `ĞœĞ¾Ğ´ĞµĞ»ÑŒ: ${found.label}` });
    try { await ctx.editMessageText(`Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: ${found.label}`); } catch {}
  });

  // Ğ ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¸ÑĞº
  b.command("web", async (ctx) => {
    const text = ctx.message.text || "";
    const q = text.replace(/^\/web(@\S+)?\s*/i, "").trim();
    if (!q) { await ctx.reply("ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ‚Ğ°Ğº: /web Ñ‚Ğ²Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ"); return; }
    await ctx.api.sendChatAction(ctx.chat.id, "typing");
    const userModel = await getUserModel(ctx.from.id);
    const model = userModel || defaultModel();
    const sr = await tavilySearch(q);
    if (!sr.ok) { await ctx.reply(sr.error === "NO_TAVILY_KEY" ? "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ TAVILY_API_KEY Ğ² Vercel" : "ĞŸĞ¾Ğ¸ÑĞº Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑÑ. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ Ğ¿Ğ¾Ğ·Ğ¶Ğµ."); return; }
    const ans = await summarizeWithSources(q, sr.data, model);
    await chunkAndReply(ctx, ans);
    await pushMessage(ctx.chat.id, { role: "user", content: `/web ${q}` });
    await pushMessage(ctx.chat.id, { role: "assistant", content: ans });
  });

  // Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚: tools Ğ´Ğ»Ñ gptâ€‘4oâ€‘mini, Ğ¿Ñ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¸ÑĞº Ğ´Ğ»Ñ Llama/Mistral
  b.on("message:text", async (ctx) => {
    const text = ctx.message.text?.trim() || "";
    if (!text) return;

    await ctx.api.sendChatAction(ctx.chat.id, "typing");

    const hist = await getHistory(ctx.chat.id);
    const userModel = await getUserModel(ctx.from.id);
    const model = userModel || defaultModel();

    try {
      let answer;
      if (FORCE_WEB_FOR_OPEN && isOpenModelNeedingWeb(model)) {
        const sr = await tavilySearch(text);
        answer = sr.ok ? await summarizeWithSources(text, sr.data, model)
                       : await plainChat({ text, hist, model });
      } else if (isToolCapableModel(model)) {
        answer = await chatWithAutoSearch({ text, hist, model });
      } else {
        answer = await plainChat({ text, hist, model });
      }

      await pushMessage(ctx.chat.id, { role: "user", content: text });
      await pushMessage(ctx.chat.id, { role: "assistant", content: answer });
      await chunkAndReply(ctx, answer);
    } catch {
      await ctx.reply("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·.");
    }
  });

  bot = b;
  return bot;
}

// â”€â”€ HTTPâ€‘Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export default async function handler(req, res) {
  if (req.method !== "POST") return res.status(200).send("OK");
  const b = getBot(); if (!b) return res.status(200).send("NO_TOKEN");
  const handle = webhookCallback(b, "http");
  try { await handle(req, res); } catch { res.status(200).end(); }
    }
