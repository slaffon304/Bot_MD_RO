import { Bot, webhookCallback, InlineKeyboard, Keyboard } from "grammy";

// â”€â”€ ĞŸÑ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ Ğ¸ Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const provider = (process.env.PROVIDER || "none").toLowerCase();
const envModel = process.env.MODEL || "";
const FORCE_WEB_FOR_OPEN = (process.env.FORCE_WEB_FOR_OPEN ?? "1") !== "0";

function defaultModel() {
  return envModel || "gpt-4o-mini"; // ÑƒĞ¼ĞµĞµÑ‚ tools
}
function isToolCapableModel(model) {
  return /gpt-4o/i.test(model);
}
function isOpenModelNeedingWeb(model) {
  return /(meta-llama|llama|mistral)/i.test(model);
}
function systemPrompt() {
  return "Ğ¢Ñ‹ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ¸ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° ÑĞ·Ñ‹ĞºĞµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ.";
}
function chunkAndReply(ctx, text) {
  const max = 3800;
  const tasks = [];
  for (let i = 0; i < text.length; i += max) {
    tasks.push(ctx.reply(text.slice(i, i + max), { reply_to_message_id: ctx.message.message_id }));
  }
  return tasks.reduce((p, t) => p.then(() => t), Promise.resolve());
}

// â”€â”€ Lazy imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function getLLMClient() {
  if (provider !== "openrouter") return null;
  const apiKey = process.env.OPENROUTER_API_KEY || "";
  if (!apiKey) return null;
  const OpenAI = (await import("openai")).default;
  return new OpenAI({ apiKey, baseURL: "https://openrouter.ai/api/v1" });
}
async function loadStore() {
  return await import("../lib/store.js");
}

// â”€â”€ I18N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const I18N = {
  ru: {
    start:
      "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ğŸ‘‹ Ğ¯ Ğ´Ğ°Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ˜Ğ˜ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑÑ‚Ğ°, ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½Ğ¾Ğº, Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ¼ÑƒĞ·Ñ‹ĞºĞ¸.\n\n" +
      "ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ğ¾Ğµ:\n" +
      "â€¢ ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ â€” Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑÑ…Ğ¾Ğ¶Ñƒ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚\n" +
      "â€¢ /model â€” Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (GPTâ€‘4oâ€‘mini, Llama, Mistral)\n" +
      "â€¢ /new â€” Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³\n" +
      "â€¢ /web Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ â€” Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¸ÑĞº\n" +
      "â€¢ /weather Ğ³Ğ¾Ñ€Ğ¾Ğ´ â€” Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° ÑĞµĞ¹Ñ‡Ğ°Ñ\n" +
      "â€¢ /subscribe â€” ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ² 06:00, /unsubscribe â€” Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ\n" +
      "â€¢ /setcity Ğ³Ğ¾Ñ€Ğ¾Ğ´ â€” Ğ³Ğ¾Ñ€Ğ¾Ğ´ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ\n" +
      "â€¢ /help â€” ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹\n\n" +
      "Ğ¡ĞºĞ¾Ñ€Ğ¾: /imagine (ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸), /video (Ğ²Ğ¸Ğ´ĞµĞ¾), /music (Ğ¼ÑƒĞ·Ñ‹ĞºĞ°), /tts (Ğ¾Ğ·Ğ²ÑƒÑ‡ĞºĞ°), /stats (ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°).",
    ask_city: "Ğ§Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€Ğ¸ÑÑ‹Ğ»Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ¿Ğ¾ ÑƒÑ‚Ñ€Ğ°Ğ¼, ÑƒĞºĞ°Ğ¶Ğ¸ Ğ³Ğ¾Ñ€Ğ¾Ğ´ Ğ¸Ğ»Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ³ĞµĞ¾Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸Ñ.",
    buttons: { send_loc: "ğŸ“ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ³ĞµĞ¾Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸Ñ", skip: "ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ" },
    saved_city: (name) => `Ğ“Ğ¾Ñ€Ğ¾Ğ´ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: ${name}`,
    saved_lang: (lang) => `Ğ¯Ğ·Ñ‹Ğº Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ°: ${lang}`,
    subscribed: "ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑĞºĞ° Ğ½Ğ° ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ°.",
    unsubscribed: "ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑĞºĞ° Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°.",
    no_tavily: "Ğ”Ğ»Ñ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒ TAVILY_API_KEY Ğ² Vercel (Production) Ğ¸ Redeploy.",
    no_llm: "Ğ˜Ğ˜ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ñ‘Ğ½. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ PROVIDER=openrouter Ğ¸ OPENROUTER_API_KEY.",
    setcity_usage: "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹: /setcity Ğ“Ğ¾Ñ€Ğ¾Ğ´\nĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: /setcity ChiÈ™inÄƒu",
    weather_now: (name, t, feels, wind, codeText) =>
      `ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ° Ğ² ${name} ÑĞµĞ¹Ñ‡Ğ°Ñ: ${t}Â°C (Ğ¾Ñ‰ÑƒÑ‰Ğ°ĞµÑ‚ÑÑ ĞºĞ°Ğº ${feels}Â°C), Ğ²ĞµÑ‚ĞµÑ€ ${wind} Ğ¼/Ñ, ${codeText}.`,
    soon: "Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞºĞ¾Ñ€Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°."
  },
  ro: {
    start:
      "Salut! ğŸ‘‹ ÃÈ›i ofer acces la AI puternic pentru text, imagini, video È™i muzicÄƒ.\n\n" +
      "Utile:\n" +
      "â€¢ Scrie un mesaj â€” dacÄƒ e nevoie, caut pe internet\n" +
      "â€¢ /model â€” alege modelul (GPTâ€‘4oâ€‘mini, Llama, Mistral)\n" +
      "â€¢ /new â€” dialog nou\n" +
      "â€¢ /web Ã®ntrebare â€” cÄƒutare web manualÄƒ\n" +
      "â€¢ /weather oraÈ™ â€” meteo acum\n" +
      "â€¢ /subscribe â€” prognozÄƒ la 06:00, /unsubscribe â€” opreÈ™te\n" +
      "â€¢ /setcity oraÈ™ â€” oraÈ™ implicit\n" +
      "â€¢ /help â€” comenzi È™i exemple\n\n" +
      "Ãn curÃ¢nd: /imagine (imagini), /video, /musicÄƒ, /tts, /stats.",
    ask_city: "Pentru prognoza de dimineaÈ›Äƒ, trimite locaÈ›ia sau seteazÄƒ oraÈ™ul.",
    buttons: { send_loc: "ğŸ“ Trimite locaÈ›ia", skip: "Omite" },
    saved_city: (name) => `OraÈ™ salvat: ${name}`,
    saved_lang: (lang) => `Limba interfeÈ›ei: ${lang}`,
    subscribed: "Ai activat abonarea la prognoza de dimineaÈ›Äƒ.",
    unsubscribed: "Ai dezactivat abonarea.",
    no_tavily: "AdaugÄƒ TAVILY_API_KEY Ã®n Vercel (Production) È™i redeploy.",
    no_llm: "AI nu este conectat. VerificÄƒ PROVIDER=openrouter È™i OPENROUTER_API_KEY.",
    setcity_usage: "FoloseÈ™te: /setcity OraÈ™\nEx.: /setcity ChiÈ™inÄƒu",
    weather_now: (name, t, feels, wind, codeText) =>
      `Vremea Ã®n ${name} acum: ${t}Â°C (se simte ca ${feels}Â°C), vÃ¢nt ${wind} m/s, ${codeText}.`,
    soon: "FuncÈ›ia va fi disponibilÄƒ Ã®n curÃ¢nd."
  },
  en: {
    start:
      "Hi! ğŸ‘‹ I give you access to strong AI for text, images, video and music.\n\n" +
      "Useful:\n" +
      "â€¢ Just type â€” Iâ€™ll browse the web when needed\n" +
      "â€¢ /model â€” choose model (GPTâ€‘4oâ€‘mini, Llama, Mistral)\n" +
      "â€¢ /new â€” new dialog\n" +
      "â€¢ /web query â€” manual web search\n" +
      "â€¢ /weather city â€” weather now\n" +
      "â€¢ /subscribe â€” morning forecast at 06:00, /unsubscribe â€” stop\n" +
      "â€¢ /setcity city â€” default city\n" +
      "â€¢ /help â€” commands and examples\n\n" +
      "Coming soon: /imagine, /video, /music, /tts, /stats.",
    ask_city: "To send morning forecast, share location or set a city.",
    buttons: { send_loc: "ğŸ“ Share location", skip: "Skip" },
    saved_city: (name) => `City saved: ${name}`,
    saved_lang: (lang) => `Interface language: ${lang}`,
    subscribed: "Morning forecast subscription is ON.",
    unsubscribed: "Subscription is OFF.",
    no_tavily: "Add TAVILY_API_KEY in Vercel (Production) and redeploy.",
    no_llm: "AI is not connected. Check PROVIDER=openrouter and OPENROUTER_API_KEY.",
    setcity_usage: "Use: /setcity City\nExample: /setcity Chisinau",
    weather_now: (name, t, feels, wind, codeText) =>
      `Weather in ${name} now: ${t}Â°C (feels like ${feels}Â°C), wind ${wind} m/s, ${codeText}.`,
    soon: "Feature coming soon."
  }
};
function langOf(ctx) {
  const lc = (ctx.from?.language_code || "en").slice(0,2).toLowerCase();
  if (lc === "ru") return "ru";
  if (lc === "ro") return "ro";
  return "en";
}

// â”€â”€ Ğ’ĞµĞ±â€‘Ğ¿Ğ¾Ğ¸ÑĞº (Tavily) + ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function tavilySearch(query, maxResults = 5) {
  const key = process.env.TAVILY_API_KEY || "";
  if (!key) return { ok: false, error: "NO_TAVILY_KEY" };
  const resp = await fetch("https://api.tavily.com/search", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      api_key: key, query,
      search_depth: "basic", include_answer: false, time_range: "d",
      max_results: Math.min(Math.max(maxResults,1),8)
    })
  });
  if (!resp.ok) return { ok:false, error:`HTTP_${resp.status}` };
  const data = await resp.json();
  return { ok:true, data };
}
async function summarizeWithSources(question, searchData, model) {
  const client = await getLLMClient();
  if (!client) throw new Error("NO_LLM");
  const sources = (searchData?.results || []).slice(0,5);
  if (!sources.length) return "ĞĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ². ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ Ğ¸Ğ½Ğ°Ñ‡Ğµ ÑÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ.";

  const list = sources.map((s,i)=>`${i+1}. ${s.title || s.url} â€” ${s.url}`).join("\n");
  const extracts = sources.map((s,i)=>`[${i+1}] ${String(s.content||"").slice(0,800)}`).join("\n\n");

  const messages = [
    {
      role:"system",
      content:"Ğ¢Ñ‹ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ„Ğ°ĞºÑ‚Ñ‹ Ğ¸Ğ· 'Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²'. Ğ”ĞµĞ»Ğ°Ğ¹ Ğ¼Ğ°Ñ€ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿ÑƒĞ½ĞºÑ‚Ñ‹. " +
              "Ğ’ Ñ‚ĞµĞºÑÑ‚Ğµ ÑÑ‚Ğ°Ğ²ÑŒ ÑÑÑ‹Ğ»ĞºĞ¸ Ğ¿Ğ¾ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ°Ğ¼ [1], [2]. Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ â€” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²."
    },
    { role:"user", content:`Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: ${question}\n\nĞ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n${list}\n\nĞ’Ñ‹Ğ´ĞµÑ€Ğ¶ĞºĞ¸:\n${extracts}` }
  ];
  const r = await client.chat.completions.create({ model, temperature:0.2, max_tokens:450, messages });
  return r.choices?.[0]?.message?.content || "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚.";
}

// â”€â”€ Ğ§Ğ°Ñ‚ Ñ€ĞµĞ¶Ğ¸Ğ¼Ñ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function plainChat({ text, hist, model }) {
  const client = await getLLMClient(); if (!client) throw new Error("NO_LLM");
  const messages = [{ role:"system", content:systemPrompt() }, ...hist, { role:"user", content:text }];
  const r = await client.chat.completions.create({ model, temperature:0.6, max_tokens:400, messages });
  return r.choices?.[0]?.message?.content || "ĞĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¾Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.";
}
async function chatWithAutoSearch({ text, hist, model }) {
  const client = await getLLMClient(); if (!client) throw new Error("NO_LLM");
  const messages = [
    { role:"system", content:"Ğ¢Ñ‹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº. Ğ•ÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ñ‹ ÑĞ²ĞµĞ¶Ğ¸Ğµ Ñ„Ğ°ĞºÑ‚Ñ‹ (Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°, ĞºÑƒÑ€ÑÑ‹, Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚.Ğ¿.), Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ web_search. Ğ˜Ğ½Ğ°Ñ‡Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ÑĞ°Ğ¼." },
    ...hist, { role:"user", content:text }
  ];
  const tools = [{
    type:"function",
    function:{
      name:"web_search",
      description:"ĞŸĞ¾Ğ¸ÑĞº Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ Ğ´Ğ»Ñ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° ÑĞ·Ñ‹ĞºĞµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ.",
      parameters:{ type:"object", properties:{ query:{type:"string"}, max_results:{type:"integer", default:5 } }, required:["query"] }
    }
  }];
  const r1 = await client.chat.completions.create({ model, temperature:0.6, max_tokens:300, messages, tools, tool_choice:"auto" });
  const msg1 = r1.choices?.[0]?.message;
  const toolCalls = msg1?.tool_calls || [];
  if (toolCalls.length > 0) {
    const call = toolCalls.find(c=>c.function?.name==="web_search") || toolCalls[0];
    let args={}; try{ args = JSON.parse(call.function?.arguments||"{}"); }catch{}
    const q = (args.query || text).toString();
    const maxRes = Number(args.max_results || 5);
    const sr = await tavilySearch(q, maxRes);
    if (!sr.ok) return sr.error==="NO_TAVILY_KEY" ? I18N.ru.no_tavily : `ĞŸĞ¾Ğ¸ÑĞº Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑÑ (${sr.error}).`;
    return await summarizeWithSources(q, sr.data, model);
  }
  const plain = msg1?.content?.trim(); if (plain) return plain;
  return "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·.";
}

// â”€â”€ Ğ“ĞµĞ¾ĞºĞ¾Ğ´Ğ¸Ğ½Ğ³ Ğ¸ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function geocodeCity(name, lang="en") {
  const url = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(name)}&count=1&language=${encodeURIComponent(lang)}&format=json`;
  const r = await fetch(url);
  if (!r.ok) return null;
  const j = await r.json();
  const p = j?.results?.[0];
  if (!p) return null;
  return { name: p.name, lat: p.latitude, lon: p.longitude, country: p.country };
}
function weatherCodeText(code, lang="ru") {
  const map = {
    0:{ru:"ÑÑĞ½Ğ¾", ro:"senin", en:"clear"},
    1:{ru:"Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼ ÑÑĞ½Ğ¾", ro:"mai mult senin", en:"mainly clear"},
    2:{ru:"Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ", ro:"parÈ›ial noros", en:"partly cloudy"},
    3:{ru:"Ğ¿Ğ°ÑĞ¼ÑƒÑ€Ğ½Ğ¾", ro:"Ã®nnorat", en:"overcast"},
    45:{ru:"Ñ‚ÑƒĞ¼Ğ°Ğ½", ro:"ceaÈ›Äƒ", en:"fog"}, 48:{ru:"Ğ¸Ğ·Ğ¼Ğ¾Ñ€Ğ¾Ğ·ÑŒ", ro:"ceaÈ›Äƒ Ã®ngheÈ›atÄƒ", en:"depositing rime fog"},
    51:{ru:"Ğ¼Ğ¾Ñ€Ğ¾ÑÑŒ ÑĞ»Ğ°Ğ±Ğ°Ñ", ro:"burniÈ›Äƒ slabÄƒ", en:"light drizzle"},
    53:{ru:"Ğ¼Ğ¾Ñ€Ğ¾ÑÑŒ", ro:"burniÈ›Äƒ", en:"drizzle"},
    55:{ru:"Ğ¼Ğ¾Ñ€Ğ¾ÑÑŒ ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ", ro:"burniÈ›Äƒ puternicÄƒ", en:"dense drizzle"},
    61:{ru:"Ğ´Ğ¾Ğ¶Ğ´ÑŒ ÑĞ»Ğ°Ğ±Ñ‹Ğ¹", ro:"ploaie slabÄƒ", en:"light rain"},
    63:{ru:"Ğ´Ğ¾Ğ¶Ğ´ÑŒ", ro:"ploaie", en:"rain"},
    65:{ru:"Ğ»Ğ¸Ğ²ĞµĞ½ÑŒ", ro:"ploaie puternicÄƒ", en:"heavy rain"},
    71:{ru:"ÑĞ½ĞµĞ³ ÑĞ»Ğ°Ğ±Ñ‹Ğ¹", ro:"ninsoare slabÄƒ", en:"light snow"},
    73:{ru:"ÑĞ½ĞµĞ³", ro:"ninsoare", en:"snow"},
    75:{ru:"ÑĞ½ĞµĞ³Ğ¾Ğ¿Ğ°Ğ´", ro:"ninsoare puternicÄƒ", en:"heavy snow"},
    80:{ru:"Ğ»Ğ¸Ğ²Ğ½Ğ¸ Ğ¼ĞµÑÑ‚Ğ°Ğ¼Ğ¸", ro:"averse locale", en:"rain showers"},
    95:{ru:"Ğ³Ñ€Ğ¾Ğ·Ğ°", ro:"furtunÄƒ", en:"thunderstorm"}
  };
  return (map[code]?.[lang]) || (map[code]?.en) || "â€”";
}
async function fetchWeatherByCoords(lat, lon) {
  const url = `https://api.open-meteo.com/v1/forecast?latitude=${lat}&longitude=${lon}&current_weather=true&timezone=auto`;
  const r = await fetch(url);
  if (!r.ok) return null;
  const j = await r.json();
  const cw = j.current_weather;
  if (!cw) return null;
  return { t: cw.temperature, wind: cw.windspeed, code: cw.weathercode, tz: j.timezone };
}

// â”€â”€ ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ /model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MODEL_OPTIONS = [
  { id: "gpt-4o-mini", label: "gpt-4o-mini (ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾/Ğ½ĞµĞ´Ğ¾Ñ€Ğ¾Ğ³Ğ¾)" },
  { id: "meta-llama/llama-3.1-70b-instruct", label: "Llama 3.1 70B (Ğ±ÑĞ´Ğ¶ĞµÑ‚)" },
  { id: "mistralai/mistral-small", label: "Mistral Small (Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾/Ğ´ĞµÑˆĞµĞ²Ğ¾)" }
];

// â”€â”€ Ğ‘Ğ¾Ñ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let bot;
function getBot() {
  if (bot) return bot;
  const token = process.env.TELEGRAM_BOT_TOKEN;
  if (!token) return null;

  const b = new Bot(token);

  // /start: Ğ°Ğ²Ñ‚Ğ¾-ÑĞ·Ñ‹Ğº, Ğ°Ğ²Ñ‚Ğ¾-Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ°, Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°/Ğ³ĞµĞ¾Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸Ğ¸ + Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ
  b.command("start", async (ctx) => {
    const { setUserLang, subscribeWeather, getUserCity } = await loadStore();
    const lc = langOf(ctx);
    await setUserLang(ctx.from.id, lc);
    await subscribeWeather(ctx.from.id);

    const t = I18N[lc] || I18N.en;
    const kb = new Keyboard()
      .requestLocation(t.buttons.send_loc)
      .row()
      .text(t.buttons.skip)
      .resized();

    const city = await getUserCity(ctx.from.id);
    if (!city) {
      await ctx.reply(t.ask_city, { reply_markup: kb });
    }
    await ctx.reply(t.start, { reply_markup: { remove_keyboard: true } });
  });

  b.command("help", async (ctx) => {
    const lc = (await (await loadStore()).getUserLang(ctx.from.id)) || langOf(ctx);
    await ctx.reply((I18N[lc]||I18N.en).start);
  });

  // Ğ¯Ğ·Ñ‹Ğº Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ: /lang ru|ro|en
  b.command("lang", async (ctx) => {
    const { setUserLang } = await loadStore();
    const arg = (ctx.message.text||"").split(/\s+/)[1]?.toLowerCase();
    const lc = ["ru","ro","en"].includes(arg) ? arg : langOf(ctx);
    await setUserLang(ctx.from.id, lc);
    await ctx.reply((I18N[lc]||I18N.en).saved_lang(lc));
  });

  // ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑĞºĞ¸
  b.command("subscribe", async (ctx) => {
    const { subscribeWeather, getUserLang } = await loadStore();
    await subscribeWeather(ctx.from.id);
    const lc = (await getUserLang(ctx.from.id)) || langOf(ctx);
    await ctx.reply((I18N[lc]||I18N.en).subscribed);
  });
  b.command("unsubscribe", async (ctx) => {
    const { unsubscribeWeather, getUserLang } = await loadStore();
    await unsubscribeWeather(ctx.from.id);
    const lc = (await getUserLang(ctx.from.id)) || langOf(ctx);
    await ctx.reply((I18N[lc]||I18N.en).unsubscribed);
  });

  // Ğ“Ğ¾Ñ€Ğ¾Ğ´: /setcity <Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ>
  b.command("setcity", async (ctx) => {
    const { setUserCity, getUserLang } = await loadStore();
    const lc = (await getUserLang(ctx.from.id)) || langOf(ctx);
    const t = I18N[lc]||I18N.en;
    const text = ctx.message.text||"";
    const name = text.replace(/^\/setcity(@\S+)?\s*/i, "").trim();
    if (!name) {
      await ctx.reply(t.setcity_usage); return;
    }
    const geo = await geocodeCity(name, lc);
    if (!geo) { await ctx.reply("City not found. / OraÈ™ul nu a fost gÄƒsit. / Ğ“Ğ¾Ñ€Ğ¾Ğ´ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½."); return; }
    await setUserCity(ctx.from.id, { name: geo.name, lat: geo.lat, lon: geo.lon });
    await ctx.reply(t.saved_city(geo.name));
  });

  // ĞŸÑ€Ğ¸Ñ‘Ğ¼ Ğ³ĞµĞ¾Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸Ğ¸
  b.on("message:location", async (ctx) => {
    const { setUserCity, getUserLang } = await loadStore();
    const lc = (await getUserLang(ctx.from.id)) || langOf(ctx);
    const t = I18N[lc]||I18N.en;
    const loc = ctx.message.location;
    if (!loc) return;
    // ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ³ĞµĞ¾ĞºĞ¾Ğ´: Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ¼ coords, Ğ¸Ğ¼Ñ Ğ´Ğ°Ğ´Ğ¸Ğ¼ "ĞœĞ¾Ñ‘ Ğ¼ĞµÑÑ‚Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ"
    await setUserCity(ctx.from.id, { name: lc==="ro"?"LocaÈ›ia mea":"ĞœĞ¾Ñ‘ Ğ¼ĞµÑÑ‚Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ", lat: loc.latitude, lon: loc.longitude });
    await ctx.reply(t.saved_city(lc==="ro"?"LocaÈ›ia mea":"ĞœĞ¾Ñ‘ Ğ¼ĞµÑÑ‚Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ"), { reply_markup: { remove_keyboard: true } });
  });

  // ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ° ÑĞµĞ¹Ñ‡Ğ°Ñ: /weather [Ğ³Ğ¾Ñ€Ğ¾Ğ´]
  b.command("weather", async (ctx) => {
    const { getUserLang, getUserCity } = await loadStore();
    const lc = (await getUserLang(ctx.from.id)) || langOf(ctx);
    const t = I18N[lc]||I18N.en;
    const text = ctx.message.text||"";
    const arg = text.replace(/^\/weather(@\S+)?\s*/i, "").trim();

    let city = null;
    if (arg) {
      const geo = await geocodeCity(arg, lc);
      if (geo) city = { name: geo.name, lat: geo.lat, lon: geo.lon };
    } else {
      city = await getUserCity(ctx.from.id);
    }
    if (!city) { await ctx.reply(t.setcity_usage); return; }

    await ctx.api.sendChatAction(ctx.chat.id, "typing");
    const w = await fetchWeatherByCoords(city.lat, city.lon);
    if (!w) { await ctx.reply("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñƒ."); return; }

    const codeText = weatherCodeText(w.code, lc);
    await ctx.reply(t.weather_now(city.name, w.t, w.t, w.wind, codeText));
  });

  // /new â€” Ğ¾Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
  b.command("new", async (ctx) => {
    const { clearHistory } = await loadStore();
    await clearHistory(ctx.chat.id);
    await ctx.reply("ĞĞºĞµĞ¹, Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³. Ğ§Ñ‚Ğ¾ Ğ´Ğ°Ğ»ÑŒÑˆĞµ?");
  });

  // Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
  b.command("model", async (ctx) => {
    const kb = new InlineKeyboard();
    for (const m of MODEL_OPTIONS) kb.text(m.label, `m:${m.id}`).row();
    await ctx.reply("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ:", { reply_markup: kb });
  });
  b.callbackQuery(/m:.+/, async (ctx) => {
    const { setUserModel } = await loadStore();
    const data = ctx.callbackQuery.data || "";
    const chosen = data.split(":")[1];
    const found = MODEL_OPTIONS.find((m)=>m.id===chosen);
    if (!found) { await ctx.answerCallbackQuery({ text:"ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ", show_alert:true }); return; }
    await setUserModel(ctx.from.id, found.id);
    await ctx.answerCallbackQuery({ text:`ĞœĞ¾Ğ´ĞµĞ»ÑŒ: ${found.label}` });
    try { await ctx.editMessageText(`Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: ${found.label}`); } catch {}
  });

  // Ğ ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¸ÑĞº
  b.command("web", async (ctx) => {
    const { pushMessage, getUserModel } = await loadStore();
    const q = (ctx.message.text||"").replace(/^\/web(@\S+)?\s*/i, "").trim();
    if (!q) { await ctx.reply("ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ‚Ğ°Ğº: /web Ñ‚Ğ²Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ"); return; }
    await ctx.api.sendChatAction(ctx.chat.id, "typing");
    const client = await getLLMClient(); if (!client) { await ctx.reply(I18N.ru.no_llm); return; }
    const userModel = await getUserModel(ctx.from.id);
    const model = userModel || defaultModel();
    const sr = await tavilySearch(q);
    if (!sr.ok) { await ctx.reply(sr.error==="NO_TAVILY_KEY" ? I18N.ru.no_tavily : `ĞŸĞ¾Ğ¸ÑĞº Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑÑ (${sr.error}).`); return; }
    const answer = await summarizeWithSources(q, sr.data, model);
    await chunkAndReply(ctx, answer);
    await pushMessage(ctx.chat.id, { role:"user", content:`/web ${q}` });
    await pushMessage(ctx.chat.id, { role:"assistant", content:answer });
  });

  // Ğ—Ğ°Ğ³Ğ»ÑƒÑˆĞºĞ¸ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ñ„Ğ¸Ñ‡ (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ ÑƒĞ¶Ğµ Ğ±Ñ‹Ğ»Ğ¸)
  for (const cmd of ["imagine","video","music","tts","stats"]) {
    b.command(cmd, async (ctx) => {
      const { getUserLang } = await loadStore();
      const lc = (await getUserLang(ctx.from.id)) || langOf(ctx);
      await ctx.reply((I18N[lc]||I18N.en).soon);
    });
  }

  // ĞĞ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚: tools Ğ´Ğ»Ñ gptâ€‘4oâ€‘mini, Ğ¿Ñ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ²ĞµĞ±â€‘Ğ¿Ğ¾Ğ¸ÑĞº Ğ´Ğ»Ñ Llama/Mistral
  b.on("message:text", async (ctx) => {
    const { getHistory, pushMessage, getUserModel } = await loadStore();
    const text = ctx.message.text?.trim() || "";
    if (!text) return;

    await ctx.api.sendChatAction(ctx.chat.id, "typing");
    const client = await getLLMClient();
    if (!client) { await ctx.reply(I18N.ru.no_llm); return; }

    const hist = await getHistory(ctx.chat.id);
    const userModel = await getUserModel(ctx.from.id);
    const model = userModel || defaultModel();

    try {
      let answer;
      if (FORCE_WEB_FOR_OPEN && isOpenModelNeedingWeb(model)) {
        const sr = await tavilySearch(text);
        answer = sr.ok ? await summarizeWithSources(text, sr.data, model)
                       : await plainChat({ text, hist, model });
      } else if (isToolCapableModel(model)) {
        answer = await chatWithAutoSearch({ text, hist, model });
      } else {
        answer = await plainChat({ text, hist, model });
      }
      await pushMessage(ctx.chat.id, { role:"user", content:text });
      await pushMessage(ctx.chat.id, { role:"assistant", content:answer });
      await chunkAndReply(ctx, answer);
    } catch (e) {
      console.error("LLM/chat error:", e);
      await ctx.reply("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·.");
    }
  });

  bot = b;
  return bot;
}

// â”€â”€ HTTP handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export default async function handler(req, res) {
  if (req.method !== "POST") return res.status(200).send("OK");
  const b = getBot();
  if (!b) return res.status(200).send("NO_TOKEN");
  const handle = webhookCallback(b, "http");
  try { await handle(req, res); } catch (e) { console.error("Webhook error:", e); res.status(200).end(); }
      }
